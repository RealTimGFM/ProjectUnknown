================================================================================
PROJECT SUMMARY
================================================================================

Generated: 2025-12-22T20:57:32Z
Root: C:\Users\User\Documents\GitHub\ProjectUnknown
Python: 3.13.5

================================================================================
PROJECT TREE
================================================================================

ProjectUnknown/
├── .github/
│   └── workflows/
│       ├── ci.yml
│       └── deploy-render.yml
├── ats_parser/
│   ├── __init__.py
│   ├── ingest.py
│   ├── llm.py
│   ├── models.py
│   ├── parser.py
│   ├── reconcile.py
│   ├── rules.py
│   └── sections.py
├── templates/
│   ├── _flash.html
│   ├── _theme.html
│   ├── admin_candidates.html
│   ├── admin_cvs.html
│   ├── admin_home.html
│   ├── admin_users.html
│   ├── auth_login.html
│   ├── auth_reset_request.html
│   ├── auth_reset_set.html
│   ├── auth_signup.html
│   └── index.html
├── tests/
│   └── test_smoke.py
├── uploads/
├── .gitattributes
├── .gitignore
├── backend.py
├── database.db
├── dump.txt
├── dump_project.py
├── Procfile
├── README.md
├── requirements.txt
└── resume_parser.py

Directories: 6  Files: 32

================================================================================
FILE CONTENTS
================================================================================

================================================================================
// Path: README.md
================================================================================

# Mini ATS — Structured Resume Scanner (Phase)

A minimal ATS-style web app:
- Upload a **PDF resume**.
- Backend parses sections and extracts **structured fields** (Experience, Education, Projects).
- Data is stored in **SQLite** with JSON columns.
- Web UI shows **text boxes per field**; you can edit and **save** back to DB.

---

## Features

- Section-aware parsing (SUMMARY / EXPERIENCE / EDUCATION / PROJECTS / SKILLS / LANGUAGES).
- Heuristics for dates and roles; calculates **duration (months)** when possible.
- Stores arrays (lists of dicts) as **JSON** in SQLite.
- Inline **edit & save** for each candidate.
- Safe parser (guards against missing sections / malformed bullets).

---
```powershell
## Project Structure
ProjectUnknown/
├─ backend.py # Flask app + DB CRUD
├─ resume_parser.py # PDF → structured JSON (experience/education/projects)
├─ templates/
│ └─ index.html # Upload + editable cards UI
├─ uploads/ # Saved resumes (created on first upload)
├─ database.db # SQLite (auto-created)
├─ requirements.txt
└─ README.md
## Quickstart
```

### 1) Create venv & install deps
**Windows (PowerShell):**
Please use Python 3.11+
```powershell
python -m venv .venv
.\.venv\Scripts\Activate.ps1
pip install -r requirements.txt

python backend.py
http://127.0.0.1:5000
# stop the app, then:
del database.db
# or
rm database.db
# start the app again so it recreates the table
The admin credential is: admin|123

# FINAL WORDS
The app is currently a prototype for school project. In order to make this better, it will need a lot of data and training. Which cannot be done with the given time and the amount of subjects I have to do at school. 

================================================================================
// Path: backend.py
================================================================================

# backend.py — Flask upload -> parse -> save -> render
from flask import (
    Flask,
    abort,
    request,
    render_template,
    jsonify,
    redirect,
    url_for,
    session,
    flash,
    send_from_directory,
)
import sqlite3, os, json, uuid
from resume_parser import parse_resume
from werkzeug.utils import secure_filename
from datetime import timedelta, datetime, timezone
from werkzeug.security import generate_password_hash, check_password_hash
import secrets
from functools import wraps


# Optional pure-Python MIME sniff (no system deps). If missing, we just skip.
try:
    import filetype  # pip install filetype
except Exception:
    filetype = None
SCHEMA_SQL = """
PRAGMA foreign_keys = ON;

CREATE TABLE IF NOT EXISTS users (
    id            INTEGER PRIMARY KEY AUTOINCREMENT,
    username      TEXT UNIQUE NOT NULL,
    password_hash TEXT NOT NULL,
    is_admin      INTEGER NOT NULL DEFAULT 0,
    active        INTEGER NOT NULL DEFAULT 1,      -- US22/US26: deactivate flag
    created_at    TEXT NOT NULL
);

CREATE TABLE IF NOT EXISTS candidates (
    id          INTEGER PRIMARY KEY AUTOINCREMENT,
    user_id     INTEGER NOT NULL,                  -- NEW: owner (US15/US27)
    name        TEXT,
    first_name  TEXT,
    middle_name TEXT,
    last_name   TEXT,
    phone       TEXT,
    email       TEXT,
    links       TEXT,                              -- JSON string
    education   TEXT,                              -- JSON string
    experience  TEXT,                              -- JSON string
    skills      TEXT,
    languages   TEXT,
    raw_text    TEXT,
    filepath    TEXT,                              -- NEW: saved file path
    created_at  TEXT NOT NULL,                     -- NEW: audit/sorting
    FOREIGN KEY(user_id) REFERENCES users(id) ON DELETE CASCADE
);

-- Optional: if you already support password resets
CREATE TABLE IF NOT EXISTS reset_tokens (
    id         INTEGER PRIMARY KEY AUTOINCREMENT,
    user_id    INTEGER NOT NULL,
    token      TEXT NOT NULL UNIQUE,
    expires_at TEXT NOT NULL,
    used       INTEGER NOT NULL DEFAULT 0,
    FOREIGN KEY(user_id) REFERENCES users(id) ON DELETE CASCADE
);
"""
app = Flask(__name__)
app.config.update(
    SESSION_COOKIE_HTTPONLY=True,
    SESSION_COOKIE_SAMESITE="Lax",
    SESSION_COOKIE_SECURE=bool(os.environ.get("COOKIE_SECURE", "0") == "1"),
)
app.secret_key = os.environ.get("SECRET_KEY", "dev-secret-change-me")
app.permanent_session_lifetime = timedelta(minutes=30)
IDLE_TIMEOUT_MIN = 15
BASE_DIR = os.path.dirname(os.path.abspath(__file__)) 
DB_PATH  = os.environ.get("DB_PATH", os.path.join(BASE_DIR, "database.db"))
UPLOAD_DIR = os.environ.get("UPLOAD_DIR", os.path.join(BASE_DIR, "uploads"))
ALLOWED_EXTS = {"pdf", "docx"}
os.makedirs(UPLOAD_DIR, exist_ok=True)
app.config["MAX_CONTENT_LENGTH"] = 10 * 1024 * 1024  # 10 MB


def allowed_file(filename: str) -> bool:
    return "." in filename and filename.rsplit(".", 1)[1].lower() in ALLOWED_EXTS


def current_user():
    uid = session.get("user_id")
    if not uid:
        return None
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute("SELECT id, username, is_admin FROM users WHERE id=?", (uid,))
    row = c.fetchone()
    conn.close()
    if not row:
        return None
    return {"id": row[0], "username": row[1], "is_admin": bool(row[2])}


def login_required(fn):

    @wraps(fn)
    def wrapper(*args, **kwargs):
        if not session.get("user_id"):
            flash("Please log in to continue.", "warn")
            return redirect(url_for("login", next=request.path))
        return fn(*args, **kwargs)

    return wrapper


def admin_required(fn):
    @wraps(fn)
    def wrapper(*args, **kwargs):
        u = current_user()
        if not (u and u.get("is_admin")):
            flash("Admin access required.", "error")
            # optional: send them back to where they tried to go
            return redirect(url_for("login", next=request.path))
        return fn(*args, **kwargs)

    return wrapper


@app.before_request
def enforce_idle_timeout():
    now = datetime.now(timezone.utc).timestamp()
    last = session.get("last_seen")
    if session.get("user_id"):
        if last and (now - last) > (IDLE_TIMEOUT_MIN * 60):
            # idle → logout
            session.clear()
            flash("You were logged out due to inactivity.", "info")
            return redirect(url_for("login"))
        session["last_seen"] = now


@app.route("/signup", methods=["GET", "POST"])
def signup():
    if request.method == "POST":
        username = (request.form.get("username") or "").strip()
        password = request.form.get("password") or ""
        if not username or not password:
            flash("Username and password are required.", "error")
            return redirect(url_for("signup"))
        conn = sqlite3.connect(DB_PATH)
        c = conn.cursor()
        try:
            c.execute(
                "INSERT INTO users (username, password_hash, created_at) VALUES (?,?,?)",
                (
                    username,
                    generate_password_hash(password),
                    datetime.now(timezone.utc).isoformat(),  # aware ISO8601
                ),
            )
            conn.commit()
        except sqlite3.IntegrityError:
            conn.close()
            flash("Username already exists.", "error")
            return redirect(url_for("signup"))
        # Auto-login after signup
        c.execute("SELECT id FROM users WHERE username=?", (username,))
        uid = c.fetchone()[0]
        conn.close()
        session.clear()
        session.permanent = True
        session["user_id"] = uid
        session["last_seen"] = datetime.now(timezone.utc).timestamp()
        flash("Account created. Welcome!", "success")
        return redirect(url_for("index"))
    return render_template("auth_signup.html")


@app.route("/login", methods=["GET", "POST"])
def login():
    if request.method == "POST":
        username = (request.form.get("username") or "").strip()
        password = request.form.get("password") or ""
        next_url = request.args.get("next") or url_for("index")

        conn = sqlite3.connect(DB_PATH)
        c = conn.cursor()
        c.execute(
            "SELECT id, password_hash, is_admin, active FROM users WHERE username=?",
            (username,),
        )
        row = c.fetchone()
        conn.close()

        if not row or not check_password_hash(row[1], password):
            import time

            time.sleep(0.5)
            flash("Invalid username or password.", "error")
            return redirect(url_for("login", next=next_url))

        if not row[3]:
            flash("Account is deactivated. Contact admin.", "error")
            return redirect(url_for("login", next=next_url))

        session.clear()
        session.permanent = True
        session["user_id"] = row[0]
        session["last_seen"] = datetime.now(timezone.utc).timestamp()
        flash("Logged in successfully.", "success")
        return redirect(next_url)
    return render_template("auth_login.html", next=request.args.get("next"))


@app.route("/logout")
def logout():
    session.clear()
    flash("Logged out.", "info")
    return redirect(url_for("login"))


@app.route("/reset/request", methods=["GET", "POST"])
def reset_request():
    if request.method == "POST":
        username = (request.form.get("username") or "").strip()
        conn = sqlite3.connect(DB_PATH)
        c = conn.cursor()
        c.execute("SELECT id FROM users WHERE username=?", (username,))
        row = c.fetchone()
        if not row:
            conn.close()
            flash("If that account exists, a reset token was created.", "info")
            return redirect(url_for("reset_request"))

        uid = row[0]
        token = secrets.token_urlsafe(24)
        expires = (datetime.now(timezone.utc) + timedelta(minutes=30)).isoformat()
        c.execute(
            "INSERT INTO reset_tokens (user_id, token, expires_at) VALUES (?,?,?)",
            (uid, token, expires),
        )
        conn.commit()
        conn.close()
        # For demo: show token and direct link
        flash(f"Reset token: {token}", "info")
        flash("Use the link below within 30 minutes.", "info")
        return redirect(url_for("reset_form", token=token))
    return render_template("auth_reset_request.html")


@app.route("/reset/<token>", methods=["GET", "POST"])
def reset_form(token):
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute(
        "SELECT user_id, expires_at, used FROM reset_tokens WHERE token=?", (token,)
    )
    row = c.fetchone()
    if not row:
        conn.close()
        flash("Invalid or expired token.", "error")
        return redirect(url_for("reset_request"))
    user_id, expires_at, used = row
    if used:
        conn.close()
        flash("This token was already used.", "error")
        return redirect(url_for("reset_request"))
    if datetime.now(timezone.utc) > datetime.fromisoformat(expires_at):
        conn.close()
        flash("Token expired.", "error")
        return redirect(url_for("reset_request"))

    if request.method == "POST":
        pw = request.form.get("password") or ""
        if len(pw) < 6:
            flash("Password must be at least 6 characters.", "error")
            return redirect(url_for("reset_form", token=token))
        c.execute(
            "UPDATE users SET password_hash=? WHERE id=?",
            (generate_password_hash(pw), user_id),
        )
        c.execute("UPDATE reset_tokens SET used=1 WHERE token=?", (token,))
        conn.commit()
        conn.close()
        flash("Password updated. Please log in.", "success")
        return redirect(url_for("login"))
    conn.close()
    return render_template("auth_reset_set.html", token=token)


@app.route("/admin")
@admin_required
def admin_home():
    return redirect(url_for("admin_candidates"))


@app.route("/admin/candidates")
@admin_required
def admin_candidates():
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute("SELECT id, name, email, phone FROM candidates ORDER BY id DESC")
    rows = c.fetchall()
    conn.close()
    return render_template("admin_candidates.html", rows=rows)


@app.post("/admin/delete/candidate/<int:cand_id>")
@admin_required
def admin_delete_candidate(cand_id: int):
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute("SELECT filepath FROM candidates WHERE id=?", (cand_id,))
    row = c.fetchone()
    if row and row[0] and os.path.exists(row[0]):
        try:
            os.remove(row[0])
        except Exception:
            pass
    c.execute("DELETE FROM candidates WHERE id=?", (cand_id,))
    conn.commit()
    conn.close()


def init_db():
    with sqlite3.connect(DB_PATH) as conn:
        conn.executescript(SCHEMA_SQL)
        c = conn.cursor()

        # ensure an admin user called 'admin' exists AND is admin+active
        from datetime import datetime, timezone
        from werkzeug.security import generate_password_hash

        c.execute("SELECT id, is_admin, active FROM users WHERE username=?", ("admin",))
        row = c.fetchone()
        if not row:
            c.execute(
                """
                INSERT INTO users (username, password_hash, is_admin, active, created_at)
                VALUES (?,?,?,?,?)
                """,
                (
                    "admin",
                    generate_password_hash("123"),
                    1,
                    1,
                    datetime.now(timezone.utc).isoformat(),
                ),
            )
        else:
            # elevate if needed
            c.execute(
                "UPDATE users SET is_admin=1, active=1 WHERE username=?", ("admin",)
            )
        conn.commit()


@app.route("/", methods=["GET"])
@login_required
def index():
    # fetch list (OPTIONAL: show only the current user's CVs)
    uid = current_user()["id"]
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute(
        """
        SELECT id, name, first_name, middle_name, last_name, phone, email, links,
               education, experience, skills, languages
        FROM candidates
        WHERE user_id=?
        ORDER BY id DESC
    """,
        (uid,),
    )
    rows = c.fetchall()
    conn.close()
    return render_template("index.html", candidates=rows, json=json, user=current_user())


@app.post("/update/<int:cand_id>")
@login_required
def update_candidate(cand_id: int):
    uid = current_user()["id"]
    with sqlite3.connect(DB_PATH) as conn:
        c = conn.cursor()
        c.execute("SELECT user_id FROM candidates WHERE id=?", (cand_id,))
        row = c.fetchone()
        if not row or row[0] != uid:
            abort(403)

    payload = request.get_json(force=True, silent=True) or {}
    name = payload.get("name", "")
    first_name = payload.get("first_name", "")
    middle_name = payload.get("middle_name", "")
    last_name = payload.get("last_name", "")
    phone = payload.get("phone", "")
    email = payload.get("email", "")
    links = json.dumps(payload.get("links", []), ensure_ascii=False)
    education = json.dumps(payload.get("education", []), ensure_ascii=False)
    experience = json.dumps(payload.get("experience", []), ensure_ascii=False)
    skills = payload.get("skills", "")
    languages = payload.get("languages", "")

    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute(
        """UPDATE candidates SET
        name=?, first_name=?, middle_name=?, last_name=?, phone=?, email=?, links=?,
        education=?, experience=?, skills=?, languages=? WHERE id=?""",
        (
            name,
            first_name,
            middle_name,
            last_name,
            phone,
            email,
            links,
            education,
            experience,
            skills,
            languages,
            cand_id,
        ),
    )
    conn.commit()
    conn.close()
    return jsonify({"ok": True})


@app.route("/admin/cvs")
@admin_required
def admin_cvs():
    base = UPLOAD_DIR
    os.makedirs(base, exist_ok=True)

    # 1) get files, newest first
    files = [
        (f, os.path.getmtime(os.path.join(base, f)))
        for f in os.listdir(base)
        if f.lower().endswith((".pdf", ".docx"))
    ]
    files.sort(key=lambda x: x[1], reverse=True)
    files = [f for f, _ in files]

    # 2) get candidates, newest first
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute(
        "SELECT id, name, first_name, middle_name, last_name FROM candidates ORDER BY id DESC"
    )
    rows = c.fetchall()
    conn.close()

    # 3) zip them
    items = []
    for i, fname in enumerate(files):
        if i < len(rows):
            cid, name, fn, mn, ln = rows[i]
            full = (
                name
                or " ".join([fn or "", mn or "", ln or ""]).strip()
                or f"Candidate #{cid}"
            )
        else:
            cid, full = None, "Unknown uploader"
        items.append({"filename": fname, "candidate_id": cid, "display_name": full})

    return render_template("admin_cvs.html", items=items)


@app.post("/upload")
@login_required
def upload():
    f = request.files.get("file")
    if not f:
        flash("No file")
        return redirect(url_for("index"))

    # extension guard
    ext = os.path.splitext(f.filename)[1].lower().lstrip(".")
    if ext not in ALLOWED_EXTS:
        flash("Unsupported file type")
        return redirect(url_for("index"))

    # save file: uploads/<userId>_<safe_name>
    uid = current_user()["id"]
    safe_name = secure_filename(f.filename)
    save_dir = UPLOAD_DIR
    os.makedirs(save_dir, exist_ok=True)
    save_path = os.path.join(save_dir, f"{uid}_{safe_name}")
    f.save(save_path)

    # parse resume
    try:
        parsed = parse_resume(save_path)
    except Exception as e:
        # cleanup on failure
        try:
            os.remove(save_path)
        except Exception:
            pass
        flash(f"Parse failed: {e}")
        return redirect(url_for("index"))

    # --- normalize fields for DB ---
    links_json = json.dumps(parsed.get("links", []), ensure_ascii=False)
    education_json = json.dumps(parsed.get("education", []), ensure_ascii=False)
    experience_json = json.dumps(parsed.get("experience", []), ensure_ascii=False)

    skills_val = parsed.get("skills", "")
    if isinstance(skills_val, list):
        skills_val = ", ".join(map(str, skills_val))

    # you said you don't need to parse languages
    languages_val = ""  # store empty; no list/JSON here

    raw_text_val = parsed.get("raw_text", "")
    now = datetime.now(timezone.utc).isoformat()

    # insert
    with sqlite3.connect(DB_PATH) as conn:
        c = conn.cursor()
        c.execute(
            """
            INSERT INTO candidates (
              user_id, name, first_name, middle_name, last_name,
              phone, email, links, education, experience,
              skills, languages, raw_text, filepath, created_at
            ) VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)
            """,
            (
                uid,
                parsed.get("name", ""),
                parsed.get("first_name", ""),
                parsed.get("middle_name", ""),
                parsed.get("last_name", ""),
                parsed.get("phone", ""),
                parsed.get("email", ""),
                links_json,
                education_json,
                experience_json,
                skills_val,
                languages_val,
                raw_text_val,
                save_path,
                now,
            ),
        )
        conn.commit()

    flash("CV uploaded")
    return redirect(url_for("index"))


def get_upload_counts():
    with sqlite3.connect(DB_PATH) as conn:
        c = conn.cursor()
        rows = c.execute(
            """
            SELECT u.id, u.username, u.active, u.is_admin, COUNT(c.id) AS uploads
            FROM users u
            LEFT JOIN candidates c ON c.user_id = u.id
            GROUP BY u.id, u.username, u.active, u.is_admin
            ORDER BY uploads DESC, u.username ASC
            """
        ).fetchall()
    return rows


@app.post("/reupload/<int:cand_id>")
@login_required
def reupload_cv(cand_id: int):
    uid = current_user()["id"]
    f = request.files.get("file")
    if not f:
        flash("No file to re-upload.", "error")
        return redirect(url_for("index"))

    ext = os.path.splitext(f.filename)[1].lower().lstrip(".")
    if ext not in {"pdf", "docx"}:
        flash("Unsupported file type", "error")
        return redirect(url_for("index"))

    # owner/admin check + get old filepath
    with sqlite3.connect(DB_PATH) as conn:
        c = conn.cursor()
        c.execute("SELECT user_id, filepath FROM candidates WHERE id=?", (cand_id,))
        row = c.fetchone()
        if not row:
            flash("Candidate not found.", "error")
            return redirect(url_for("index"))
        owner_id, old_path = row
        u = current_user()
        if not (u["is_admin"] or owner_id == uid):
            abort(403)

    # save new file
    safe_name = secure_filename(f.filename)
    save_dir =  UPLOAD_DIR
    os.makedirs(save_dir, exist_ok=True)
    save_path = os.path.join(save_dir, f"{uid}_{safe_name}")
    f.save(save_path)

    # parse
    try:
        parsed = parse_resume(save_path)
    except Exception as e:
        try:
            os.remove(save_path)
        except Exception:
            pass
        flash(f"Parse failed: {e}", "error")
        return redirect(url_for("index"))

    # --- normalize fields for DB ---
    links_json = json.dumps(parsed.get("links", []), ensure_ascii=False)
    education_json = json.dumps(parsed.get("education", []), ensure_ascii=False)
    experience_json = json.dumps(parsed.get("experience", []), ensure_ascii=False)

    skills_val = parsed.get("skills", "")
    if isinstance(skills_val, list):
        skills_val = ", ".join(map(str, skills_val))

    # you said you don't need to parse languages
    languages_val = ""  # store empty; no list/JSON here

    raw_text_val = parsed.get("raw_text", "")
    now = datetime.now(timezone.utc).isoformat()

    # update candidate
    with sqlite3.connect(DB_PATH) as conn:
        c = conn.cursor()
        c.execute(
            """
            UPDATE candidates SET
              name=?, first_name=?, middle_name=?, last_name=?,
              phone=?, email=?, links=?, education=?, experience=?,
              skills=?, languages=?, raw_text=?, filepath=?, created_at=?
            WHERE id=?
            """,
            (
                parsed.get("name", ""),
                parsed.get("first_name", ""),
                parsed.get("middle_name", ""),
                parsed.get("last_name", ""),
                parsed.get("phone", ""),
                parsed.get("email", ""),
                links_json,
                education_json,
                experience_json,
                skills_val,
                languages_val,
                raw_text_val,
                save_path,
                now,
                cand_id,
            ),
        )
        conn.commit()

    # remove old file after successful update
    if old_path and os.path.exists(old_path):
        try:
            os.remove(old_path)
        except Exception:
            pass

    flash("CV re-uploaded & parsed.", "success")
    return redirect(url_for("index"))


@app.post("/account/delete")
@login_required
def account_delete():
    uid = current_user()["id"]
    pw = request.form.get("password") or ""
    with sqlite3.connect(DB_PATH) as conn:
        c = conn.cursor()
        c.execute("SELECT password_hash FROM users WHERE id=?", (uid,))
        row = c.fetchone()
        if not row or not check_password_hash(row[0], pw):
            flash("Password incorrect.", "error")
            return redirect(url_for("index"))
        c.execute("SELECT filepath FROM candidates WHERE user_id=?", (uid,))
        for (fp,) in c.fetchall():
            if fp and os.path.exists(fp):
                try:
                    os.remove(fp)
                except Exception:
                    pass
        c.execute("DELETE FROM users WHERE id=?", (uid,))
        conn.commit()
    session.clear()
    flash("Account and all uploads deleted.", "success")
    return redirect(url_for("login"))


@app.post("/cv/delete/<int:cand_id>")
@login_required
def delete_cv(cand_id: int):
    uid = current_user()["id"]
    with sqlite3.connect(DB_PATH) as conn:
        c = conn.cursor()
        c.execute("SELECT user_id, filepath FROM candidates WHERE id=?", (cand_id,))
        row = c.fetchone()
        if not row:
            flash("Not found.", "error")
            return redirect(url_for("index"))
        owner_id, fpath = row
        u = current_user()
        if not (u["is_admin"] or owner_id == uid):
            abort(403)
        if fpath and os.path.exists(fpath):
            try:
                os.remove(fpath)
            except Exception:
                pass
        c.execute("DELETE FROM candidates WHERE id=?", (cand_id,))
        conn.commit()
    flash(f"Deleted CV #{cand_id}.", "success")
    return redirect(url_for("index"))


@app.get("/admin/users")
@admin_required
def admin_users():
    rows = get_upload_counts()
    return render_template("admin_users.html", rows=rows)


@app.route("/admin/cvs/<path:filename>")
@admin_required
def admin_download_cv(filename):
    return send_from_directory(UPLOAD_DIR, filename, as_attachment=True)


@app.post("/admin/users/<int:uid>/deactivate")
@admin_required
def deactivate_user(uid: int):
    with sqlite3.connect(DB_PATH) as conn:
        conn.execute("UPDATE users SET active=0 WHERE id=?", (uid,))
        conn.commit()
    flash(f"User #{uid} deactivated.", "success")
    return redirect(url_for("admin_users"))


@app.post("/admin/users/<int:uid>/activate")
@admin_required
def activate_user(uid: int):
    with sqlite3.connect(DB_PATH) as conn:
        conn.execute("UPDATE users SET active=1 WHERE id=?", (uid,))
        conn.commit()
    flash(f"User #{uid} activated.", "success")
    return redirect(url_for("admin_users"))


@app.post("/admin/users/<int:uid>/reset")
@admin_required
def admin_reset_user(uid: int):
    token = secrets.token_urlsafe(24)
    expires = (datetime.now(timezone.utc) + timedelta(hours=1)).isoformat()
    with sqlite3.connect(DB_PATH) as conn:
        conn.execute(
            "INSERT INTO reset_tokens (user_id, token, expires_at) VALUES (?,?,?)",
            (uid, token, expires),
        )
        conn.commit()
    flash(f"Reset link: {url_for('reset_form', token=token, _external=False)}", "info")
    return redirect(url_for("admin_users"))

@app.get("/healthz")
def healthz():
    return "ok", 200

init_db()
if __name__ == "__main__":

    app.run(debug=False)


================================================================================
// Path: dump.txt
================================================================================

================================================================================
PROJECT SUMMARY
================================================================================

Generated: 2025-12-22T20:57:32Z
Root: C:\Users\User\Documents\GitHub\ProjectUnknown
Python: 3.13.5

================================================================================
PROJECT TREE
================================================================================

ProjectUnknown/
├── .github/
│   └── workflows/
│       ├── ci.yml
│       └── deploy-render.yml
├── ats_parser/
│   ├── __init__.py
│   ├── ingest.py
│   ├── llm.py
│   ├── models.py
│   ├── parser.py
│   ├── reconcile.py
│   ├── rules.py
│   └── sections.py
├── templates/
│   ├── _flash.html
│   ├── _theme.html
│   ├── admin_candidates.html
│   ├── admin_cvs.html
│   ├── admin_home.html
│   ├── admin_users.html
│   ├── auth_login.html
│   ├── auth_reset_request.html
│   ├── auth_reset_set.html
│   ├── auth_signup.html
│   └── index.html
├── tests/
│   └── test_smoke.py
├── uploads/
├── .gitattributes
├── .gitignore
├── backend.py
├── database.db
├── dump.txt
├── dump_project.py
├── Procfile
├── README.md
├── requirements.txt
└── resume_parser.py

Directories: 6  Files: 32

================================================================================
FILE CONTENTS
================================================================================

================================================================================
// Path: README.md
================================================================================

# Mini ATS — Structured Resume Scanner (Phase)

A minimal ATS-style web app:
- Upload a **PDF resume**.
- Backend parses sections and extracts **structured fields** (Experience, Education, Projects).
- Data is stored in **SQLite** with JSON columns.
- Web UI shows **text boxes per field**; you can edit and **save** back to DB.

---

## Features

- Section-aware parsing (SUMMARY / EXPERIENCE / EDUCATION / PROJECTS / SKILLS / LANGUAGES).
- Heuristics for dates and roles; calculates **duration (months)** when possible.
- Stores arrays (lists of dicts) as **JSON** in SQLite.
- Inline **edit & save** for each candidate.
- Safe parser (guards against missing sections / malformed bullets).

---
```powershell
## Project Structure
ProjectUnknown/
├─ backend.py # Flask app + DB CRUD
├─ resume_parser.py # PDF → structured JSON (experience/education/projects)
├─ templates/
│ └─ index.html # Upload + editable cards UI
├─ uploads/ # Saved resumes (created on first upload)
├─ database.db # SQLite (auto-created)
├─ requirements.txt
└─ README.md
## Quickstart
```

### 1) Create venv & install deps
**Windows (PowerShell):**
Please use Python 3.11+
```powershell
python -m venv .venv
.\.venv\Scripts\Activate.ps1
pip install -r requirements.txt

python backend.py
http://127.0.0.1:5000
# stop the app, then:
del database.db
# or
rm database.db
# start the app again so it recreates the table
The admin credential is: admin|123

# FINAL WORDS
The app is currently a prototype for school project. In order to make this better, it will need a lot of data and training. Which cannot be done with the given time and the amount of subjects I have to do at school. 

================================================================================
// Path: backend.py
================================================================================

# backend.py — Flask upload -> parse -> save -> render
from flask import (
    Flask,
    abort,
    request,
    render_template,
    jsonify,
    redirect,
    url_for,
    session,
    flash,
    send_from_directory,
)
import sqlite3, os, json, uuid
from resume_parser import parse_resume
from werkzeug.utils import secure_filename
from datetime import timedelta, datetime, timezone
from werkzeug.security import generate_password_hash, check_password_hash
import secrets
from functools import wraps


# Optional pure-Python MIME sniff (no system deps). If missing, we just skip.
try:
    import filetype  # pip install filetype
except Exception:
    filetype = None
SCHEMA_SQL = """
PRAGMA foreign_keys = ON;

CREATE TABLE IF NOT EXISTS users (
    id            INTEGER PRIMARY KEY AUTOINCREMENT,
    username      TEXT UNIQUE NOT NULL,
    password_hash TEXT NOT NULL,
    is_admin      INTEGER NOT NULL DEFAULT 0,
    active        INTEGER NOT NULL DEFAULT 1,      -- US22/US26: deactivate flag
    created_at    TEXT NOT NULL
);

CREATE TABLE IF NOT EXISTS candidates (
    id          INTEGER PRIMARY KEY AUTOINCREMENT,
    user_id     INTEGER NOT NULL,                  -- NEW: owner (US15/US27)
    name        TEXT,
    first_name  TEXT,
    middle_name TEXT,
    last_name   TEXT,
    phone       TEXT,
    email       TEXT,
    links       TEXT,                              -- JSON string
    education   TEXT,                              -- JSON string
    experience  TEXT,                              -- JSON string
    skills      TEXT,
    languages   TEXT,
    raw_text    TEXT,
    filepath    TEXT,                              -- NEW: saved file path
    created_at  TEXT NOT NULL,                     -- NEW: audit/sorting
    FOREIGN KEY(user_id) REFERENCES users(id) ON DELETE CASCADE
);

-- Optional: if you already support password resets
CREATE TABLE IF NOT EXISTS reset_tokens (
    id         INTEGER PRIMARY KEY AUTOINCREMENT,
    user_id    INTEGER NOT NULL,
    token      TEXT NOT NULL UNIQUE,
    expires_at TEXT NOT NULL,
    used       INTEGER NOT NULL DEFAULT 0,
    FOREIGN KEY(user_id) REFERENCES users(id) ON DELETE CASCADE
);
"""
app = Flask(__name__)
app.config.update(
    SESSION_COOKIE_HTTPONLY=True,
    SESSION_COOKIE_SAMESITE="Lax",
    SESSION_COOKIE_SECURE=bool(os.environ.get("COOKIE_SECURE", "0") == "1"),
)
app.secret_key = os.environ.get("SECRET_KEY", "dev-secret-change-me")
app.permanent_session_lifetime = timedelta(minutes=30)
IDLE_TIMEOUT_MIN = 15
BASE_DIR = os.path.dirname(os.path.abspath(__file__)) 
DB_PATH  = os.environ.get("DB_PATH", os.path.join(BASE_DIR, "database.db"))
UPLOAD_DIR = os.environ.get("UPLOAD_DIR", os.path.join(BASE_DIR, "uploads"))
ALLOWED_EXTS = {"pdf", "docx"}
os.makedirs(UPLOAD_DIR, exist_ok=True)
app.config["MAX_CONTENT_LENGTH"] = 10 * 1024 * 1024  # 10 MB


def allowed_file(filename: str) -> bool:
    return "." in filename and filename.rsplit(".", 1)[1].lower() in ALLOWED_EXTS


def current_user():
    uid = session.get("user_id")
    if not uid:
        return None
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute("SELECT id, username, is_admin FROM users WHERE id=?", (uid,))
    row = c.fetchone()
    conn.close()
    if not row:
        return None
    return {"id": row[0], "username": row[1], "is_admin": bool(row[2])}


def login_required(fn):

    @wraps(fn)
    def wrapper(*args, **kwargs):
        if not session.get("user_id"):
            flash("Please log in to continue.", "warn")
            return redirect(url_for("login", next=request.path))
        return fn(*args, **kwargs)

    return wrapper


def admin_required(fn):
    @wraps(fn)
    def wrapper(*args, **kwargs):
        u = current_user()
        if not (u and u.get("is_admin")):
            flash("Admin access required.", "error")
            # optional: send them back to where they tried to go
            return redirect(url_for("login", next=request.path))
        return fn(*args, **kwargs)

    return wrapper


@app.before_request
def enforce_idle_timeout():
    now = datetime.now(timezone.utc).timestamp()
    last = session.get("last_seen")
    if session.get("user_id"):
        if last and (now - last) > (IDLE_TIMEOUT_MIN * 60):
            # idle → logout
            session.clear()
            flash("You were logged out due to inactivity.", "info")
            return redirect(url_for("login"))
        session["last_seen"] = now


@app.route("/signup", methods=["GET", "POST"])
def signup():
    if request.method == "POST":
        username = (request.form.get("username") or "").strip()
        password = request.form.get("password") or ""
        if not username or not password:
            flash("Username and password are required.", "error")
            return redirect(url_for("signup"))
        conn = sqlite3.connect(DB_PATH)
        c = conn.cursor()
        try:
            c.execute(
                "INSERT INTO users (username, password_hash, created_at) VALUES (?,?,?)",
                (
                    username,
                    generate_password_hash(password),
                    datetime.now(timezone.utc).isoformat(),  # aware ISO8601
                ),
            )
            conn.commit()
        except sqlite3.IntegrityError:
            conn.close()
            flash("Username already exists.", "error")
            return redirect(url_for("signup"))
        # Auto-login after signup
        c.execute("SELECT id FROM users WHERE username=?", (username,))
        uid = c.fetchone()[0]
        conn.close()
        session.clear()
        session.permanent = True
        session["user_id"] = uid
        session["last_seen"] = datetime.now(timezone.utc).timestamp()
        flash("Account created. Welcome!", "success")
        return redirect(url_for("index"))
    return render_template("auth_signup.html")


@app.route("/login", methods=["GET", "POST"])
def login():
    if request.method == "POST":
        username = (request.form.get("username") or "").strip()
        password = request.form.get("password") or ""
        next_url = request.args.get("next") or url_for("index")

        conn = sqlite3.connect(DB_PATH)
        c = conn.cursor()
        c.execute(
            "SELECT id, password_hash, is_admin, active FROM users WHERE username=?",
            (username,),
        )
        row = c.fetchone()
        conn.close()

        if not row or not check_password_hash(row[1], password):
            import time

            time.sleep(0.5)
            flash("Invalid username or password.", "error")
            return redirect(url_for("login", next=next_url))

        if not row[3]:
            flash("Account is deactivated. Contact admin.", "error")
            return redirect(url_for("login", next=next_url))

        session.clear()
        session.permanent = True
        session["user_id"] = row[0]
        session["last_seen"] = datetime.now(timezone.utc).timestamp()
        flash("Logged in successfully.", "success")
        return redirect(next_url)
    return render_template("auth_login.html", next=request.args.get("next"))


@app.route("/logout")
def logout():
    session.clear()
    flash("Logged out.", "info")
    return redirect(url_for("login"))


@app.route("/reset/request", methods=["GET", "POST"])
def reset_request():
    if request.method == "POST":
        username = (request.form.get("username") or "").strip()
        conn = sqlite3.connect(DB_PATH)
        c = conn.cursor()
        c.execute("SELECT id FROM users WHERE username=?", (username,))
        row = c.fetchone()
        if not row:
            conn.close()
            flash("If that account exists, a reset token was created.", "info")
            return redirect(url_for("reset_request"))

        uid = row[0]
        token = secrets.token_urlsafe(24)
        expires = (datetime.now(timezone.utc) + timedelta(minutes=30)).isoformat()
        c.execute(
            "INSERT INTO reset_tokens (user_id, token, expires_at) VALUES (?,?,?)",
            (uid, token, expires),
        )
        conn.commit()
        conn.close()
        # For demo: show token and direct link
        flash(f"Reset token: {token}", "info")
        flash("Use the link below within 30 minutes.", "info")
        return redirect(url_for("reset_form", token=token))
    return render_template("auth_reset_request.html")


@app.route("/reset/<token>", methods=["GET", "POST"])
def reset_form(token):
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute(
        "SELECT user_id, expires_at, used FROM reset_tokens WHERE token=?", (token,)
    )
    row = c.fetchone()
    if not row:
        conn.close()
        flash("Invalid or expired token.", "error")
        return redirect(url_for("reset_request"))
    user_id, expires_at, used = row
    if used:
        conn.close()
        flash("This token was already used.", "error")
        return redirect(url_for("reset_request"))
    if datetime.now(timezone.utc) > datetime.fromisoformat(expires_at):
        conn.close()
        flash("Token expired.", "error")
        return redirect(url_for("reset_request"))

    if request.method == "POST":
        pw = request.form.get("password") or ""
        if len(pw) < 6:
            flash("Password must be at least 6 characters.", "error")
            return redirect(url_for("reset_form", token=token))
        c.execute(
            "UPDATE users SET password_hash=? WHERE id=?",
            (generate_password_hash(pw), user_id),
        )
        c.execute("UPDATE reset_tokens SET used=1 WHERE token=?", (token,))
        conn.commit()
        conn.close()
        flash("Password updated. Please log in.", "success")
        return redirect(url_for("login"))
    conn.close()
    return render_template("auth_reset_set.html", token=token)


@app.route("/admin")
@admin_required
def admin_home():
    return redirect(url_for("admin_candidates"))


@app.route("/admin/candidates")
@admin_required
def admin_candidates():
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute("SELECT id, name, email, phone FROM candidates ORDER BY id DESC")
    rows = c.fetchall()
    conn.close()
    return render_template("admin_candidates.html", rows=rows)


@app.post("/admin/delete/candidate/<int:cand_id>")
@admin_required
def admin_delete_candidate(cand_id: int):
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute("SELECT filepath FROM candidates WHERE id=?", (cand_id,))
    row = c.fetchone()
    if row and row[0] and os.path.exists(row[0]):
        try:
            os.remove(row[0])
        except Exception:
            pass
    c.execute("DELETE FROM candidates WHERE id=?", (cand_id,))
    conn.commit()
    conn.close()


def init_db():
    with sqlite3.connect(DB_PATH) as conn:
        conn.executescript(SCHEMA_SQL)
        c = conn.cursor()

        # ensure an admin user called 'admin' exists AND is admin+active
        from datetime import datetime, timezone
        from werkzeug.security import generate_password_hash

        c.execute("SELECT id, is_admin, active FROM users WHERE username=?", ("admin",))
        row = c.fetchone()
        if not row:
            c.execute(
                """
                INSERT INTO users (username, password_hash, is_admin, active, created_at)
                VALUES (?,?,?,?,?)
                """,
                (
                    "admin",
                    generate_password_hash("123"),
                    1,
                    1,
                    datetime.now(timezone.utc).isoformat(),
                ),
            )
        else:
            # elevate if needed
            c.execute(
                "UPDATE users SET is_admin=1, active=1 WHERE username=?", ("admin",)
            )
        conn.commit()


@app.route("/", methods=["GET"])
@login_required
def index():
    # fetch list (OPTIONAL: show only the current user's CVs)
    uid = current_user()["id"]
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute(
        """
        SELECT id, name, first_name, middle_name, last_name, phone, email, links,
               education, experience, skills, languages
        FROM candidates
        WHERE user_id=?
        ORDER BY id DESC
    """,
        (uid,),
    )
    rows = c.fetchall()
    conn.close()
    return render_template("index.html", candidates=rows, json=json, user=current_user())


@app.post("/update/<int:cand_id>")
@login_required
def update_candidate(cand_id: int):
    uid = current_user()["id"]
    with sqlite3.connect(DB_PATH) as conn:
        c = conn.cursor()
        c.execute("SELECT user_id FROM candidates WHERE id=?", (cand_id,))
        row = c.fetchone()
        if not row or row[0] != uid:
            abort(403)

    payload = request.get_json(force=True, silent=True) or {}
    name = payload.get("name", "")
    first_name = payload.get("first_name", "")
    middle_name = payload.get("middle_name", "")
    last_name = payload.get("last_name", "")
    phone = payload.get("phone", "")
    email = payload.get("email", "")
    links = json.dumps(payload.get("links", []), ensure_ascii=False)
    education = json.dumps(payload.get("education", []), ensure_ascii=False)
    experience = json.dumps(payload.get("experience", []), ensure_ascii=False)
    skills = payload.get("skills", "")
    languages = payload.get("languages", "")

    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute(
        """UPDATE candidates SET
        name=?, first_name=?, middle_name=?, last_name=?, phone=?, email=?, links=?,
        education=?, experience=?, skills=?, languages=? WHERE id=?""",
        (
            name,
            first_name,
            middle_name,
            last_name,
            phone,
            email,
            links,
            education,
            experience,
            skills,
            languages,
            cand_id,
        ),
    )
    conn.commit()
    conn.close()
    return jsonify({"ok": True})


@app.route("/admin/cvs")
@admin_required
def admin_cvs():
    base = UPLOAD_DIR
    os.makedirs(base, exist_ok=True)

    # 1) get files, newest first
    files = [
        (f, os.path.getmtime(os.path.join(base, f)))
        for f in os.listdir(base)
        if f.lower().endswith((".pdf", ".docx"))
    ]
    files.sort(key=lambda x: x[1], reverse=True)
    files = [f for f, _ in files]

    # 2) get candidates, newest first
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute(
        "SELECT id, name, first_name, middle_name, last_name FROM candidates ORDER BY id DESC"
    )
    rows = c.fetchall()
    conn.close()

    # 3) zip them
    items = []
    for i, fname in enumerate(files):
        if i < len(rows):
            cid, name, fn, mn, ln = rows[i]
            full = (
                name
                or " ".join([fn or "", mn or "", ln or ""]).strip()
                or f"Candidate #{cid}"
            )
        else:
            cid, full = None, "Unknown uploader"
        items.append({"filename": fname, "candidate_id": cid, "display_name": full})

    return render_template("admin_cvs.html", items=items)


@app.post("/upload")
@login_required
def upload():
    f = request.files.get("file")
    if not f:
        flash("No file")
        return redirect(url_for("index"))

    # extension guard
    ext = os.path.splitext(f.filename)[1].lower().lstrip(".")
    if ext not in ALLOWED_EXTS:
        flash("Unsupported file type")
        return redirect(url_for("index"))

    # save file: uploads/<userId>_<safe_name>
    uid = current_user()["id"]
    safe_name = secure_filename(f.filename)
    save_dir = UPLOAD_DIR
    os.makedirs(save_dir, exist_ok=True)
    save_path = os.path.join(save_dir, f"{uid}_{safe_name}")
    f.save(save_path)

    # parse resume
    try:
        parsed = parse_resume(save_path)
    except Exception as e:
        # cleanup on failure
        try:
            os.remove(save_path)
        except Exception:
            pass
        flash(f"Parse failed: {e}")
        return redirect(url_for("index"))

    # --- normalize fields for DB ---
    links_json = json.dumps(parsed.get("links", []), ensure_ascii=False)
    education_json = json.dumps(parsed.get("education", []), ensure_ascii=False)
    experience_json = json.dumps(parsed.get("experience", []), ensure_ascii=False)

    skills_val = parsed.get("skills", "")
    if isinstance(skills_val, list):
        skills_val = ", ".join(map(str, skills_val))

    # you said you don't need to parse languages
    languages_val = ""  # store empty; no list/JSON here

    raw_text_val = parsed.get("raw_text", "")
    now = datetime.now(timezone.utc).isoformat()

    # insert
    with sqlite3.connect(DB_PATH) as conn:
        c = conn.cursor()
        c.execute(
            """
            INSERT INTO candidates (
              user_id, name, first_name, middle_name, last_name,
              phone, email, links, education, experience,
              skills, languages, raw_text, filepath, created_at
            ) VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)
            """,
            (
                uid,
                parsed.get("name", ""),
                parsed.get("first_name", ""),
                parsed.get("middle_name", ""),
                parsed.get("last_name", ""),
                parsed.get("phone", ""),
                parsed.get("email", ""),
                links_json,
                education_json,
                experience_json,
                skills_val,
                languages_val,
                raw_text_val,
                save_path,
                now,
            ),
        )
        conn.commit()

    flash("CV uploaded")
    return redirect(url_for("index"))


def get_upload_counts():
    with sqlite3.connect(DB_PATH) as conn:
        c = conn.cursor()
        rows = c.execute(
            """
            SELECT u.id, u.username, u.active, u.is_admin, COUNT(c.id) AS uploads
            FROM users u
            LEFT JOIN candidates c ON c.user_id = u.id
            GROUP BY u.id, u.username, u.active, u.is_admin
            ORDER BY uploads DESC, u.username ASC
            """
        ).fetchall()
    return rows


@app.post("/reupload/<int:cand_id>")
@login_required
def reupload_cv(cand_id: int):
    uid = current_user()["id"]
    f = request.files.get("file")
    if not f:
        flash("No file to re-upload.", "error")
        return redirect(url_for("index"))

    ext = os.path.splitext(f.filename)[1].lower().lstrip(".")
    if ext not in {"pdf", "docx"}:
        flash("Unsupported file type", "error")
        return redirect(url_for("index"))

    # owner/admin check + get old filepath
    with sqlite3.connect(DB_PATH) as conn:
        c = conn.cursor()
        c.execute("SELECT user_id, filepath FROM candidates WHERE id=?", (cand_id,))
        row = c.fetchone()
        if not row:
            flash("Candidate not found.", "error")
            return redirect(url_for("index"))
        owner_id, old_path = row
        u = current_user()
        if not (u["is_admin"] or owner_id == uid):
            abort(403)

    # save new file
    safe_name = secure_filename(f.filename)
    save_dir =  UPLOAD_DIR
    os.makedirs(save_dir, exist_ok=True)
    save_path = os.path.join(save_dir, f"{uid}_{safe_name}")
    f.save(save_path)

    # parse
    try:
        parsed = parse_resume(save_path)
    except Exception as e:
        try:
            os.remove(save_path)
        except Exception:
            pass
        flash(f"Parse failed: {e}", "error")
        return redirect(url_for("index"))

    # --- normalize fields for DB ---
    links_json = json.dumps(parsed.get("links", []), ensure_ascii=False)
    education_json = json.dumps(parsed.get("education", []), ensure_ascii=False)
    experience_json = json.dumps(parsed.get("experience", []), ensure_ascii=False)

    skills_val = parsed.get("skills", "")
    if isinstance(skills_val, list):
        skills_val = ", ".join(map(str, skills_val))

    # you said you don't need to parse languages
    languages_val = ""  # store empty; no list/JSON here

    raw_text_val = parsed.get("raw_text", "")
    now = datetime.now(timezone.utc).isoformat()

    # update candidate
    with sqlite3.connect(DB_PATH) as conn:
        c = conn.cursor()
        c.execute(
            """
            UPDATE candidates SET
              name=?, first_name=?, middle_name=?, last_name=?,
              phone=?, email=?, links=?, education=?, experience=?,
              skills=?, languages=?, raw_text=?, filepath=?, created_at=?
            WHERE id=?
            """,
            (
                parsed.get("name", ""),
                parsed.get("first_name", ""),
                parsed.get("middle_name", ""),
                parsed.get("last_name", ""),
                parsed.get("phone", ""),
                parsed.get("email", ""),
                links_json,
                education_json,
                experience_json,
                skills_val,
                languages_val,
                raw_text_val,
                save_path,
                now,
                cand_id,
            ),
        )
        conn.commit()

    # remove old file after successful update
    if old_path and os.path.exists(old_path):
        try:
            os.remove(old_path)
        except Exception:
            pass

    flash("CV re-uploaded & parsed.", "success")
    return redirect(url_for("index"))


@app.post("/account/delete")
@login_required
def account_delete():
    uid = current_user()["id"]
    pw = request.form.get("password") or ""
    with sqlite3.connect(DB_PATH) as conn:
        c = conn.cursor()
        c.execute("SELECT password_hash FROM users WHERE id=?", (uid,))
        row = c.fetchone()
        if not row or not check_password_hash(row[0], pw):
            flash("Password incorrect.", "error")
            return redirect(url_for("index"))
        c.execute("SELECT filepath FROM candidates WHERE user_id=?", (uid,))
        for (fp,) in c.fetchall():
            if fp and os.path.exists(fp):
                try:
                    os.remove(fp)
                except Exception:
                    pass
        c.execute("DELETE FROM users WHERE id=?", (uid,))
        conn.commit()
    session.clear()
    flash("Account and all uploads deleted.", "success")
    return redirect(url_for("login"))


@app.post("/cv/delete/<int:cand_id>")
@login_required
def delete_cv(cand_id: int):
    uid = current_user()["id"]
    with sqlite3.connect(DB_PATH) as conn:
        c = conn.cursor()
        c.execute("SELECT user_id, filepath FROM candidates WHERE id=?", (cand_id,))
        row = c.fetchone()
        if not row:
            flash("Not found.", "error")
            return redirect(url_for("index"))
        owner_id, fpath = row
        u = current_user()
        if not (u["is_admin"] or owner_id == uid):
            abort(403)
        if fpath and os.path.exists(fpath):
            try:
                os.remove(fpath)
            except Exception:
                pass
        c.execute("DELETE FROM candidates WHERE id=?", (cand_id,))
        conn.commit()
    flash(f"Deleted CV #{cand_id}.", "success")
    return redirect(url_for("index"))


@app.get("/admin/users")
@admin_required
def admin_users():
    rows = get_upload_counts()
    return render_template("admin_users.html", rows=rows)


@app.route("/admin/cvs/<path:filename>")
@admin_required
def admin_download_cv(filename):
    return send_from_directory(UPLOAD_DIR, filename, as_attachment=True)


@app.post("/admin/users/<int:uid>/deactivate")
@admin_required
def deactivate_user(uid: int):
    with sqlite3.connect(DB_PATH) as conn:
        conn.execute("UPDATE users SET active=0 WHERE id=?", (uid,))
        conn.commit()
    flash(f"User #{uid} deactivated.", "success")
    return redirect(url_for("admin_users"))


@app.post("/admin/users/<int:uid>/activate")
@admin_required
def activate_user(uid: int):
    with sqlite3.connect(DB_PATH) as conn:
        conn.execute("UPDATE users SET active=1 WHERE id=?", (uid,))
        conn.commit()
    flash(f"User #{uid} activated.", "success")
    return redirect(url_for("admin_users"))


@app.post("/admin/users/<int:uid>/reset")
@admin_required
def admin_reset_user(uid: int):
    token = secrets.token_urlsafe(24)
    expires = (datetime.now(timezone.utc) + timedelta(hours=1)).isoformat()
    with sqlite3.connect(DB_PATH) as conn:
        conn.execute(
            "INSERT INTO reset_tokens (user_id, token, expires_at) VALUES (?,?,?)",
            (uid, token, expires),
        )
        conn.commit()
    flash(f"Reset link: {url_for('reset_form', token=token, _external=False)}", "info")
    return redirect(url_for("admin_users"))

@app.get("/healthz")
def healthz():
    return "ok", 200

init_db()
if __name__ == "__main__":

    app.run(debug=False)


================================================================================
// Path: dump_project.py
================================================================================

import os
import sys
import argparse
from datetime import datetime
from typing import Iterable, List, Set, Tuple

# ---------- Defaults tuned for StockAI ----------
DEFAULT_ROOT = "."
DEFAULT_OUTPUT = "dump.txt"
DEFAULT_MAX_FILE_SIZE = 1 * 1024 * 1024  # 1 MB

# Folders we usually exclude from **tree** to avoid noise; use --tree-all to include anyway
TREE_EXCLUDE_ANYWHERE: Set[str] = {".git", ".venv", "__pycache__", ".idea", ".vscode"}

# Folders we exclude from **content**, but still show in the tree
CONTENT_EXCLUDE_ANYWHERE: Set[str] = {
    ".git", ".venv", "__pycache__", ".idea", ".vscode", "node_modules",
    "dist", "build", ".mastra",
    # project artifacts
    "backtests", "notebooks",
}

# Filenames to ignore for content
IGNORE_FILES_ANYWHERE: Set[str] = {
    ".env", ".env.local", ".python-version", "Pipfile.lock",
    "package-lock.json", "tsconfig.json", "cookies.txt",
}

# Always include these names (even without extensions) in content
INCLUDE_FILENAMES: Set[str] = {"Makefile", "Dockerfile"}

# Binary-ish extensions (content skipped; still listed in tree)
BINARY_EXTS: Set[str] = {
    # archives / binaries
    ".zip", ".gz", ".tar", ".rar", ".7z", ".exe", ".dll", ".so", ".a",
    # db / parquet / arrow
    ".sqlite", ".sqlite3", ".db", ".db-journal", ".parquet", ".arrow",
    # images
    ".png", ".jpg", ".jpeg", ".gif", ".bmp", ".tiff", ".ico", ".webp",
    # docs
    ".pdf", ".doc", ".docx", ".ppt", ".pptx", ".xls", ".xlsx",
    # audio/video
    ".mp3", ".wav", ".m4a", ".mp4", ".mov", ".avi", ".mkv",
}

# Text/code extensions included by default for content
DEFAULT_INCLUDE_EXTS: Set[str] = {
    ".py", ".toml", ".yaml", ".yml", ".json", ".md", ".txt", ".cfg", ".ini",
    ".sql", ".sh", ".bat", ".ps1", ".html", ".css", ".js", ".ts", ".tsx", ".jsx",
}
# ------------------------------------------------

def parse_args():
    p = argparse.ArgumentParser(description="Dump project TREE + text/code contents into a single file.")
    p.add_argument("--root", default=DEFAULT_ROOT, help="Root directory to scan")
    p.add_argument("--output", default=DEFAULT_OUTPUT, help="Output file path")
    p.add_argument("--max-size", type=int, default=DEFAULT_MAX_FILE_SIZE, help="Max file size (bytes) for content")
    p.add_argument("--include-ext", default=",".join(sorted(DEFAULT_INCLUDE_EXTS)),
                   help="Comma-separated list of file extensions to include as content (e.g. .py,.toml,.yaml)")
    p.add_argument("--tree-all", action="store_true", help="Include ALL directories in the tree (even .git/.venv)")
    p.add_argument("--no-content", action="store_true", help="Only print the tree (no file contents)")
    p.add_argument("--placeholders", action="store_true",
                   help="Write placeholder blocks for skipped files (binary/large/not-included)")
    return p.parse_args()

def _normalize_exts(s: str) -> Set[str]:
    exts = set()
    for raw in s.split(","):
        e = raw.strip()
        if not e:
            continue
        if not e.startswith("."):
            e = "." + e
        exts.add(e.lower())
    return exts

def is_probably_binary(filepath: str, chunk_size: int = 1024) -> bool:
    try:
        with open(filepath, "rb") as f:
            chunk = f.read(chunk_size)
            if not chunk:
                return False
            if b"\0" in chunk:
                return True
            text_chars = bytearray({7,8,9,10,12,13,27} | set(range(0x20, 0x100)) - {0x7F})
            non_text = sum(1 for b in chunk if b not in text_chars)
            return (non_text / max(1, len(chunk))) > 0.30
    except Exception:
        return True

def should_hide_in_tree(name: str, include_all: bool) -> bool:
    return (name in TREE_EXCLUDE_ANYWHERE) and (not include_all)

def should_skip_content_dir(name: str) -> bool:
    return name in CONTENT_EXCLUDE_ANYWHERE

def should_include_content(fname: str, include_exts: Set[str]) -> bool:
    if fname in INCLUDE_FILENAMES:
        return True
    base, ext = os.path.splitext(fname)
    ext = ext.lower()
    if ext in BINARY_EXTS:
        return False
    if include_exts and ext not in include_exts:
        return False
    return True

def tree_lines(root: str, include_all: bool) -> Tuple[List[str], int, int]:
    """
    Return (lines, dir_count, file_count) for a pretty tree.
    """
    lines: List[str] = []
    dir_count = 0
    file_count = 0

    def walk(dir_path: str, prefix: str = ""):
        nonlocal dir_count, file_count
        try:
            entries = sorted(os.scandir(dir_path), key=lambda e: (not e.is_dir(), e.name.lower()))
        except PermissionError:
            return
        # filter only for tree display
        entries = [e for e in entries if not (e.is_dir() and should_hide_in_tree(e.name, include_all))]
        total = len(entries)
        for idx, e in enumerate(entries):
            connector = "└── " if idx == total - 1 else "├── "
            if e.is_dir():
                lines.append(f"{prefix}{connector}{e.name}/")
                dir_count += 1
                next_prefix = f"{prefix}{'    ' if idx == total - 1 else '│   '}"
                walk(e.path, next_prefix)
            else:
                file_count += 1
                lines.append(f"{prefix}{connector}{e.name}")

    root_label = os.path.basename(os.path.abspath(root)) or root
    lines.append(f"{root_label}/")
    walk(root)
    return lines, dir_count, file_count

def write_header(dump, title: str):
    sep = "=" * max(80, len(title) + 10)
    dump.write(f"{sep}\n")
    dump.write(f"{title}\n")
    dump.write(f"{sep}\n\n")

def write_file_header(dump, rel_path: str):
    header = f"// Path: {rel_path}"
    sep_len = max(80, len(header))
    dump.write("=" * sep_len + "\n")
    dump.write(header + "\n")
    dump.write("=" * sep_len + "\n\n")

def iter_all_files(root: str) -> Iterable[str]:
    for cur_root, dirs, files in os.walk(root, topdown=True):
        dirs[:] = sorted(dirs)
        for fname in sorted(files):
            yield os.path.join(cur_root, fname)

def main():
    args = parse_args()
    root = args.root
    out_path = args.output
    include_exts = _normalize_exts(args.include_ext)

    if not os.path.isdir(root):
        print(f"ERROR: root directory not found: {root}")
        sys.exit(1)

    with open(out_path, "w", encoding="utf-8", errors="ignore") as dump:
        # 1) Project metadata
        write_header(dump, "PROJECT SUMMARY")
        dump.write(f"Generated: {datetime.utcnow().isoformat(timespec='seconds')}Z\n")
        dump.write(f"Root: {os.path.abspath(root)}\n")
        dump.write(f"Python: {sys.version.split()[0]}\n\n")

        # 2) Tree
        write_header(dump, "PROJECT TREE")
        lines, dcnt, fcnt = tree_lines(root, include_all=args.tree_all)
        dump.write("\n".join(lines) + "\n\n")
        dump.write(f"Directories: {dcnt}  Files: {fcnt}\n\n")

        if args.no_content:
            print(f"Done (tree only). Wrote {out_path}")
            return

        # 3) File contents (text/code only)
        write_header(dump, "FILE CONTENTS")
        processed = 0
        skipped = 0

        for fpath in iter_all_files(root):
            rel = os.path.relpath(fpath, root).replace("\\", "/")
            fname = os.path.basename(fpath)
            parent = os.path.basename(os.path.dirname(fpath))

            # Skip content if under excluded dirs
            if parent in CONTENT_EXCLUDE_ANYWHERE or any(p in CONTENT_EXCLUDE_ANYWHERE for p in rel.split("/") if p):
                # still optionally write placeholder
                if args.placeholders:
                    write_file_header(dump, rel)
                    dump.write(f"// [skipped: directory excluded from content]\n\n")
                skipped += 1
                continue

            # Skip content by rule
            if not should_include_content(fname, include_exts):
                if args.placeholders:
                    write_file_header(dump, rel)
                    dump.write(f"// [skipped: extension not in include list]\n\n")
                skipped += 1
                continue

            # Size & binary checks
            try:
                size = os.path.getsize(fpath)
            except OSError as e:
                if args.placeholders:
                    write_file_header(dump, rel)
                    dump.write(f"// [skipped: stat error: {e}]\n\n")
                skipped += 1
                continue

            if size > args.max_size:
                if args.placeholders:
                    write_file_header(dump, rel)
                    dump.write(f"// [skipped: large file ~{size} bytes]\n\n")
                skipped += 1
                continue

            if is_probably_binary(fpath):
                if args.placeholders:
                    write_file_header(dump, rel)
                    dump.write(f"// [skipped: binary-like file]\n\n")
                skipped += 1
                continue

            # Emit content
            try:
                with open(fpath, "r", encoding="utf-8", errors="ignore") as src:
                    content = src.read()
                write_file_header(dump, rel)
                dump.write(content)
                dump.write("\n\n")
                processed += 1
                if processed % 50 == 0:
                    print(f"... wrote {processed} files")
            except Exception as e:
                if args.placeholders:
                    write_file_header(dump, rel)
                    dump.write(f"// [skipped: read error: {e}]\n\n")
                skipped += 1
                continue

        dump.write(f"\n// Summary: wrote {processed} files, skipped {skipped} files.\n")

    print(f"Done. TREE + contents written to {out_path}")

if __name__ == "__main__":
    main()


================================================================================
// Path: requirements.txt
================================================================================

# --- Web (Flask app you have now) ---
Flask>=3.0.3
Werkzeug>=3.0.3
Jinja2>=3.1.4
itsdangerous>=2.2.0
click>=8.1.7
gunicorn
pytest

# --- PDF parsing (pip-only) ---
PyMuPDF>=1.24
pdfplumber>=0.11
pdfminer.six>=20231228

# --- OCR fallback (no system deps) ---
easyocr>=1.7.2
torch>=2.3          # CPU wheel

# --- NLP / parsing helpers ---
regex>=2024.9.11
python-dateutil>=2.9.0.post0
phonenumbers>=8.13.44
email-validator>=2.2.0

# --- Optional, pure-Python file type sniffing used in backend.py (safe to keep) ---
filetype>=1.2.0

# --- Nice-to-have logs ---
rich>=13.8

# --- NLP ---
spacy>=3.7
srsly>=2.4
typer>=0.12

# optional but useful:
spacy-lookups-data>=1.0

# --- New/updated deps for ats_parser (hybrid parser) ---
pydantic>=2.7
rapidfuzz>=3.9
langdetect>=1.0.9
httpx>=0.27
requests>=2.32
openai>=1.40        # only needed if USE_LLM=1

dateparser>=1.2
python-docx>=1.1.0


================================================================================
// Path: resume_parser.py
================================================================================

from __future__ import annotations
import os
from typing import Dict

from ats_parser import parse_file, adapt_for_backend

def parse_resume(filepath: str) -> Dict:
    """
    Entry point that supports both PDF and DOCX.
    For PDF: identical behavior as before (parse_file -> adapt_for_backend).
    For DOCX: extracts text via python-docx, then tries ats_parser text pipeline.
    """
    ext = os.path.splitext(filepath)[1].lower()

    if ext == ".pdf":
        res = parse_file(filepath)
        return adapt_for_backend(res)

    if ext == ".docx":
        # 1) Extract text from DOCX
        try:
            from docx import Document
        except ImportError as e:
            raise RuntimeError(
                "python-docx is not installed. Run: pip install python-docx"
            ) from e

        doc = Document(filepath)
        text = "\n".join(p.text for p in doc.paragraphs).strip()

        try:
            from ats_parser import parse_text  # optional, only if exists
            res = parse_text(text)
            return adapt_for_backend(res)
        except Exception:
            # 3) Fallback: use sections/rules directly, then flatten into your dict shape
            #    This keeps things resilient if parse_text does not exist in your build.
            try:
                from ats_parser import sections, rules
            except Exception as inner_e:
                # If your repo doesn't expose sections/rules, surface the root cause
                raise RuntimeError(
                    "ats_parser text pipeline not available. "
                    "Expose parse_text() or sections/rules in ats_parser."
                ) from inner_e

            # --- very lightweight text → fields pass ---
            secs = sections.split_sections(text)
            contacts = rules.extract_contacts(text) or {}
            skills = rules.extract_skills(secs.get("SKILLS", "")) or ""
            education = rules.fallback_education(secs.get("EDUCATION", ""))
            experience = rules.fallback_experience(secs.get("EXPERIENCE", ""))
            languages = rules.extract_languages(secs.get("LANGUAGES", "")) if hasattr(rules, "extract_languages") else ""
            projects = rules.extract_projects(secs.get("PROJECTS", "")) if hasattr(rules, "extract_projects") else ""

            return {
                "raw_text": text,
                "name": contacts.get("name", ""),
                "first_name": contacts.get("first_name", ""),
                "middle_name": contacts.get("middle_name", ""),
                "last_name": contacts.get("last_name", ""),
                "phone": contacts.get("phone", ""),
                "email": contacts.get("email", ""),
                "links": contacts.get("links", []),
                "skills": skills,
                "education": education,
                "experience": experience,
                "languages": languages,
                "projects": projects,
            }
    raise ValueError(f"Unsupported file type: {ext}")


================================================================================
// Path: .github/workflows/ci.yml
================================================================================

name: CI

on:
  push:
    branches: ["main"]
  pull_request:
    branches: ["main"]

jobs:
  test:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install minimal deps for tests
        run: |
          python -m pip install --upgrade pip
          pip install Flask Werkzeug pytest

      - name: Run tests
        run: |
          pytest -q


================================================================================
// Path: .github/workflows/deploy-render.yml
================================================================================

name: Deploy to Render

on:
  push:
    branches: [main]
  workflow_dispatch:

permissions:
  contents: read

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - name: Trigger Render deploy hook
        env:
          RENDER_DEPLOY_HOOK_URL: ${{ secrets.RENDER_DEPLOY_HOOK_URL }}
        run: |
          if [ -z "${RENDER_DEPLOY_HOOK_URL:-}" ]; then
            echo "Missing secret: RENDER_DEPLOY_HOOK_URL"
            echo "Add it in GitHub: Settings -> Secrets and variables -> Actions"
            exit 1
          fi

          curl -fsSL -X POST "$RENDER_DEPLOY_HOOK_URL"
          echo "Render deploy triggered."


================================================================================
// Path: ats_parser/__init__.py
================================================================================


"""Hybrid resume parser package (rules + optional LLM)."""
from .parser import parse_file, parse_bytes, adapt_for_backend


================================================================================
// Path: ats_parser/ingest.py
================================================================================


from __future__ import annotations
import os, re, unicodedata
from typing import Tuple
import fitz  # PyMuPDF
import pdfplumber

USE_OCR = os.getenv("USE_OCR", "0") == "1"
OCR_LANGS = (os.getenv("OCR_LANGS", "en").split(","))

def _norm_ws(s: str) -> str:
    if not s:
        return ""
    s = s.replace("\ufeff", "")
    s = "".join(" " if (ch.isspace() or unicodedata.category(ch) == "Zs") else ch for ch in s)
    return re.sub(r"\s+", " ", s).strip()

def _page_blocks_sorted(page):
    blocks = page.get_text("blocks") or []
    blocks.sort(key=lambda b: (round(b[1],1), round(b[0],1)))
    return blocks

def _blocks_to_text(blocks):
    lines = []
    for b in blocks:
        t = (b[4] or "").strip()
        if t:
            lines.append(t)
    return "\n".join(lines)

_ocr_reader = None
def _get_ocr():
    global _ocr_reader
    if _ocr_reader is None:
        import easyocr  # lazy
        _ocr_reader = easyocr.Reader(OCR_LANGS, gpu=False)
    return _ocr_reader

def read_pdf_text(path: str) -> Tuple[str, int]:
    """Return (text, ocr_pages_used). Uses blocks; falls back to text/ocr/pdfplumber."""
    doc = fitz.open(path)
    assembled, ocr_count = [], 0
    for i, page in enumerate(doc):
        raw = _blocks_to_text(_page_blocks_sorted(page)) or (page.get_text("text") or "")
        if len(_norm_ws(raw)) < 120 and USE_OCR:
            # high-res pix + OCR
            mat = fitz.Matrix(300/72, 300/72).preRotate((page.rotation or 0)%360)
            pix = page.get_pixmap(matrix=mat, alpha=False)
            img = pix.tobytes("png")
            reader = _get_ocr()
            lines = reader.readtext(img, detail=0, paragraph=True)
            raw = "\n".join(l.strip() for l in lines if l and l.strip())
            ocr_count += 1
        assembled.append(raw)
    doc.close()
    text = "\n".join(assembled).strip()

    # rescue with pdfplumber if still sparse
    if len(_norm_ws(text)) < 120:
        try:
            with pdfplumber.open(path) as pdf:
                text2 = "\n".join((p.extract_text() or "") for p in pdf.pages)
            if len(_norm_ws(text2)) > len(_norm_ws(text)):
                text = text2
        except Exception:
            pass

    return (text or "") + "\n", ocr_count


================================================================================
// Path: ats_parser/llm.py
================================================================================

from typing import List
import os, json, requests
from .models import ExperienceItem, DateSpan, EducationItem  


USE_LLM = os.getenv("USE_LLM", "0") == "1"


def extract_experience_llm(text: str) -> List[ExperienceItem]:
    """
    LLM extractor for EXPERIENCE.
    - Requires USE_LLM=1 and OPENAI_API_KEY.
    - Enforces a JSON *array* via json_schema.
    """
    if not USE_LLM or not (text or "").strip():
        return []
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        return []

    model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
    schema = {
        "name": "experience_array",
        "schema": {
            "type": "array",
            "items": {
                "type": "object",
                "properties": {
                    "title": {"type": "string"},
                    "company": {"type": "string"},
                    "location": {"type": "string"},
                    "dates": {
                        "type": "object",
                        "properties": {
                            "start": {"type": ["string", "null"]},
                            "end": {"type": ["string", "null"]},
                            "months": {"type": ["integer", "null"]},
                        },
                    },
                    "bullets": {"type": "array", "items": {"type": "string"}},
                    "technologies": {"type": "array", "items": {"type": "string"}},
                    "confidence": {"type": "number"},
                },
                "required": ["title", "company", "dates", "bullets"],
            },
        },
        "strict": True,
    }

    prompt = f"""Extract the candidate's work EXPERIENCE from the text.
Return a JSON array. Dates must be YYYY-MM or null. If end date is current, set end to "Present".
Text:
{text}
"""

    try:
        r = requests.post(
            "https://api.openai.com/v1/responses",
            headers={
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json",
            },
            json={
                "model": model,
                "input": prompt,
                "response_format": {"type": "json_schema", "json_schema": schema},
                "max_output_tokens": 2000,
            },
            timeout=45,
        )
        data = r.json()
        # Responses API (preferred)
        out_text = ""
        try:
            out_text = data["output"][0]["content"][0]["text"]
        except Exception:
            # Chat-style fallback
            out_text = (
                data.get("choices", [{}])[0].get("message", {}).get("content", "")
            )

        arr = json.loads(out_text) if out_text else []
        if not isinstance(arr, list):
            return []
        out: List[ExperienceItem] = []
        for it in arr:
            out.append(
                ExperienceItem(
                    title=it.get("title", ""),
                    company=it.get("company", ""),
                    location=it.get("location", ""),
                    dates=DateSpan(**(it.get("dates") or {})),
                    bullets=it.get("bullets") or [],
                    technologies=it.get("technologies") or [],
                    confidence=float(it.get("confidence") or 0.8),
                )
            )
        return out
    except Exception:
        return []
def extract_education_llm(text: str) -> List[EducationItem]:
    if not USE_LLM or not (text or "").strip():
        return []
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        return []

    model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
    schema = {
        "name": "education_array",
        "schema": {
            "type": "array",
            "items": {
                "type":"object",
                "properties":{
                    "degree":{"type":"string"},
                    "field":{"type":"string"},
                    "school":{"type":"string"},
                    "location":{"type":"string"},
                    "dates":{"type":"object","properties":{
                        "start":{"type":["string","null"]},
                        "end":{"type":["string","null"]},
                        "months":{"type":["integer","null"]}
                    }},
                    "gpa":{"type":["string","null"]}
                },
                "required":["degree","school","dates"]
            }
        },
        "strict": True
    }

    prompt = f"""Extract EDUCATION entries as a JSON array.
Each item: degree, field, school, location, dates.start YYYY-MM or null, dates.end YYYY-MM or 'Present' or null, months may be null, gpa optional.
Text:
{text}
"""
    try:
        r = requests.post(
            "https://api.openai.com/v1/responses",
            headers={"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"},
            json={
                "model": model,
                "input": prompt,
                "response_format": {"type":"json_schema","json_schema": schema},
                "max_output_tokens": 1200
            },
            timeout=45
        )
        data = r.json()
        out_text = ""
        try:
            out_text = data["output"][0]["content"][0]["text"]
        except Exception:
            out_text = data.get("choices", [{}])[0].get("message", {}).get("content", "")
        arr = json.loads(out_text) if out_text else []
        if not isinstance(arr, list):
            return []
        out: List[EducationItem] = []
        for it in arr:
            out.append(EducationItem(
                degree=it.get("degree",""),
                field=it.get("field",""),
                school=it.get("school",""),
                location=it.get("location",""),
                dates=DateSpan(**(it.get("dates") or {})),
                gpa=it.get("gpa")
            ))
        return out
    except Exception:
        return []

================================================================================
// Path: ats_parser/models.py
================================================================================


from __future__ import annotations
from pydantic import BaseModel, Field, EmailStr, HttpUrl, ConfigDict
from typing import List, Optional

class DateSpan(BaseModel):
    start: Optional[str] = Field(default=None, description="YYYY-MM or None")
    end: Optional[str] = Field(default=None, description="YYYY-MM or 'Present' or None")
    months: Optional[int] = None

class ExperienceItem(BaseModel):
    title: Optional[str] = ""
    company: Optional[str] = ""
    location: Optional[str] = ""
    dates: DateSpan = DateSpan()
    bullets: List[str] = []
    technologies: List[str] = []
    confidence: float = 0.0

class EducationItem(BaseModel):
    degree: Optional[str] = ""
    field: Optional[str] = ""
    school: Optional[str] = ""
    location: Optional[str] = ""
    dates: DateSpan = DateSpan()
    gpa: Optional[str] = None

class Contact(BaseModel):
    name: Optional[str] = ""
    email: Optional[EmailStr] = None
    phone: Optional[str] = None
    location: Optional[str] = None
    linkedin: Optional[HttpUrl] = None
    github: Optional[HttpUrl] = None
    websites: List[HttpUrl] = []

class Resume(BaseModel):
    model_config = ConfigDict(arbitrary_types_allowed=True)
    contact: Contact = Contact()
    summary: Optional[str] = ""
    skills: List[str] = []
    experience: List[ExperienceItem] = []
    education: List[EducationItem] = []
    certifications: List[str] = []
    languages: List[str] = []
    raw_text: str = ""
    flags: dict = {}


================================================================================
// Path: ats_parser/parser.py
================================================================================

from __future__ import annotations
from typing import List
from .models import Resume, Contact, ExperienceItem, EducationItem, DateSpan
from .ingest import read_pdf_text
from .sections import split_sections
from . import rules
from .llm import extract_experience_llm, extract_education_llm
from .reconcile import merge_experience


def _split_name(full: str):
    s = (full or "").strip()
    if not s:
        return "", "", ""
    parts = s.split()
    if len(parts) == 1:
        return parts[0], "", ""
    if len(parts) == 2:
        return parts[0], "", parts[1]
    return parts[0], " ".join(parts[1:-1]), parts[-1]


def parse_file(path: str) -> Resume:
    text, ocr_pages = read_pdf_text(path)
    secs = split_sections(text)

    contacts = rules.extract_contacts(text)
    skills_list = rules.extract_skills(secs.get("SKILLS", []))
    if not skills_list:
        # fallback if the splitter missed the section heading
        skills_list = rules.extract_skills_from_text(text)


    exp_rule = [
        ExperienceItem(
            title=it["title"],
            company=it["company"],
            location=it["location"],
            dates=DateSpan(**it["dates"]),
            bullets=it["bullets"],
            technologies=it["technologies"],
            confidence=it.get("confidence", 0.55),
        )
        for it in rules.fallback_experience(secs.get("EXPERIENCE") or text)
    ]
    if not exp_rule:
        exp_rule = [
            ExperienceItem(
                title=it["title"],
                company=it["company"],
                location=it["location"],
                dates=DateSpan(**it["dates"]),
                bullets=it["bullets"],
                technologies=it["technologies"],
                confidence=it.get("confidence", 0.55),
            )
            for it in rules.fallback_experience(text)
        ]
    # ----- EDUCATION -----
    edu_lines = secs.get("EDUCATION") or []
    edu_rule = [
        EducationItem(
            degree=it["degree"],
            field=it["field"],
            school=it["school"],
            location=it["location"],
            dates=DateSpan(**it["dates"]),
            gpa=it.get("gpa"),
        )
        for it in (rules.fallback_education(edu_lines) if edu_lines else [])
    ]

    edu_llm: List[EducationItem] = extract_education_llm("\n".join(edu_lines)) or []

    # Prefer deterministic rules; fall back to LLM only if rules found nothing
    education = edu_rule or edu_llm

    exp_llm: List[ExperienceItem] = (
        extract_experience_llm("\n".join(secs.get("EXPERIENCE", []))) or []
    )

    experience = merge_experience(exp_rule, exp_llm)

    resume = Resume(
        contact=Contact(
            name=contacts.get("name", ""),
            email=contacts.get("email") or None,
            phone=contacts.get("phone") or None,
            websites=contacts.get("links") or [],
        ),
        summary=" ".join(secs.get("SUMMARY", [])[:5]),
        skills=skills_list,
        experience=experience,
        education=education,
        certifications=[],
        languages=[],
        raw_text=text,
        flags={
            "used_ocr": bool(ocr_pages),
            "sections_found": {k: len(v or []) for k, v in secs.items()},
        },
    )
    return resume


def parse_bytes(data: bytes) -> Resume:
    import tempfile, os

    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
        tmp.write(data)
        tmp.flush()
        path = tmp.name
    try:
        return parse_file(path)
    finally:
        try:
            os.remove(path)
        except Exception:
            pass


def adapt_for_backend(resume: Resume) -> dict:
    name = resume.contact.name or ""

    def _split_name(full: str):
        s = (full or "").strip()
        if not s:
            return "", "", ""
        parts = s.split()
        if len(parts) == 1:
            return parts[0], "", ""
        if len(parts) == 2:
            return parts[0], "", parts[1]
        return parts[0], " ".join(parts[1:-1]), parts[-1]

    first, middle, last = _split_name(name)

    # Flatten experience for your UI
    exp_flat = []
    for e in resume.experience:
        exp_flat.append(
            {
                "position": e.title or "",
                "company_name": e.company or "",
                "location": e.location or "",
                "start_date": (e.dates.start or ""),
                "end_date": (e.dates.end or ""),
                "duration_months": e.dates.months,
                "description": "\n".join(e.bullets).strip(),
            }
        )

    # Flatten education similarly (if you add education later)
    edu_flat = []
    for ed in resume.education:
        sy = (ed.dates.start or "")[:4] if (ed.dates and ed.dates.start) else ""
        if ed.dates and ed.dates.end == "Present":
            ey = "Present"
        else:
            ey = (ed.dates.end or "")[:4] if (ed.dates and ed.dates.end) else ""
        edu_flat.append(
            {
                "level": ed.degree or "",
                "field": ed.field or "",
                "school_name": ed.school or "",
                "location": ed.location or "",
                "start_year": sy,
                "end_year": ey,
            }
        )

    return {
        "name": name,
        "first_name": first,
        "middle_name": middle,
        "last_name": last,
        "phone": resume.contact.phone or "",
        "email": str(resume.contact.email) if resume.contact.email else "",
        "links": [str(u) for u in (resume.contact.websites or [])],
        "education": edu_flat,  # <- flattened for your template
        "experience": exp_flat,  # <- flattened for your template
        "skills": ", ".join(resume.skills),
        "languages": ", ".join(resume.languages),
        "raw_text": resume.raw_text,
    }


================================================================================
// Path: ats_parser/reconcile.py
================================================================================

from __future__ import annotations
from typing import List
from rapidfuzz import fuzz
from .models import ExperienceItem


def dedupe_keep_order(items: List[str]) -> List[str]:
    seen = set()
    out = []
    for s in items:
        key = s.strip().lower()
        if key and key not in seen:
            seen.add(key)
            out.append(s.strip())
    return out


def merge_experience(
    rule_items: List[ExperienceItem], llm_items: List[ExperienceItem]
) -> List[ExperienceItem]:
    if not llm_items:
        return rule_items
    if not rule_items:
        return llm_items
    out: List[ExperienceItem] = []
    used = [False] * len(llm_items)
    for r in rule_items:
        best_i, best = -1, 0
        for i, l in enumerate(llm_items):
            if used[i]:
                continue
            score = 0
            if r.company and l.company:
                score += fuzz.token_set_ratio(r.company, l.company)
            if r.title and l.title:
                score += fuzz.token_set_ratio(r.title, l.title)
            if score > best:
                best = score
                best_i = i
        if best >= 120:
            l = llm_items[best_i]
            used[best_i] = True
            merged = ExperienceItem(
                title=l.title or r.title,
                company=l.company or r.company,
                location=l.location or r.location,
                dates=l.dates if (l.dates.start or l.dates.end) else r.dates,
                bullets=l.bullets or r.bullets,
                technologies=list({*r.technologies, *l.technologies}),
                confidence=max(r.confidence, l.confidence),
            )
            out.append(merged)
        else:
            out.append(r)
    for i, l in enumerate(llm_items):
        if not used[i]:
            out.append(l)
    return out


================================================================================
// Path: ats_parser/rules.py
================================================================================

from __future__ import annotations
import re
from typing import List, Tuple
from datetime import datetime
import phonenumbers

try:
    import dateparser
except Exception:
    dateparser = None

LOCATION_HINT = re.compile(
    r"\b("
    r"QC|ON|BC|AB|MB|SK|NS|NB|NL|PE|PEI|YT|NT|NU|CA|USA|US|UK|"
    r"Quebec|Ontario|British Columbia|Alberta|Manitoba|Saskatchewan|"
    r"Nova Scotia|New Brunswick|Newfoundland|Prince Edward Island|"
    r"Montreal|Toronto|Vancouver|Calgary|Edmonton|Ottawa|Winnipeg|"
    r"Regina|Saskatoon|Quebec City|Charlottetown"
    r")\b",
    re.I,
)

EMAIL = re.compile(r"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}")
LINK = re.compile(r"\b(?:https?://|www\.)[^\s)]+", re.I)
MONTHS = (
    r"(?:Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|Jun(?:e)?|"
    r"Jul(?:y)?|Aug(?:ust)?|Sep(?:t|tember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?)"
)
YEAR = r"(?:19|20)\d{2}"
NUM_MMYYYY = r"(?:0?[1-9]|1[0-2])[-/\.](?:\d{4})"
PRESENT = r"(?:Present|Current|Now|Today)"
RANGE_SEP = r"(?:\s*(?:-|–|—|to)\s*)"
DATE_TOKEN = rf"(?:{MONTHS}\s+{YEAR}|{YEAR}|{NUM_MMYYYY})"
DATE_RE = re.compile(
    rf"(?P<start>{DATE_TOKEN}){RANGE_SEP}(?P<end>{DATE_TOKEN}|{PRESENT})", re.I
)

BULLET = re.compile(r"^(\s*[-•‣∙·*]\s+)")
TITLE_HINT = re.compile(
    r"\b(senior|sr\.?|jr\.?|junior|lead|principal|staff|head|director|manager|"
    r"engineer|developer|analyst|consultant|architect|intern)\b",
    re.I,
)
COMPANY_SUFFIX = re.compile(
    r"\b(inc\.?|corp\.?|llc|ltd\.?|co\.?|company|capital|fund|bank|group|partners?|"
    r"systems?|labs?|studio|technolog(?:y|ies)|solutions?)\b",
    re.I,
)

MONTH_MAP = {
    "jan": 1,
    "january": 1,
    "feb": 2,
    "february": 2,
    "mar": 3,
    "march": 3,
    "apr": 4,
    "april": 4,
    "may": 5,
    "jun": 6,
    "june": 6,
    "jul": 7,
    "july": 7,
    "aug": 8,
    "august": 8,
    "sep": 9,
    "sept": 9,
    "september": 9,
    "oct": 10,
    "october": 10,
    "nov": 11,
    "november": 11,
    "dec": 12,
    "december": 12,
}

# Degree / school patterns
DEGREE_HINT = re.compile(
    r"\b("
    r"(?:bachelo[u]?r|master|msc|ma|mba|m\.?eng|b\.?sc|b\.?eng|ph\.?d|phd|doctoral|doctorate|"
    r"diploma|degree|certificat(?:e)?|dec|d\.?e\.?c|high\s+school|secondary|college\s+studies)"
    r")\b",
    re.I,
)
SCHOOL_SUFFIX = re.compile(
    r"\b(universit(?:y|é)|university|college|school|institute|academy|polytechnique|école)\b",
    re.I,
)
# ------- Skills lexicon (small but effective) -------
# canonical name -> list of regex fragments (lowercase)
_SKILL_CANON = {
    "Python": [r"\bpython\b"],
    "Java": [r"\bjava\b"],
    "JavaScript": [r"\bjavascript\b", r"\bjs\b(?!x)"],
    "TypeScript": [r"\btypescript\b", r"\bts\b(?!v)"],
    "C#": [r"\bc\#\b", r"\bc[-\s]?sharp\b"],
    "C++": [r"\bc\+\+\b"],
    "C": [r"\bc\b(?!\+\+|\s*#)\b"],
    ".NET": [r"\b\.?net(?:\s*core)?\b"],
    "Node.js": [r"\bnode(?:\.js)?\b"],
    "React": [r"\breact(?:\.js|js)?\b"],
    "Next.js": [r"\bnext(?:\.js)?\b"],
    "Vue": [r"\bvue(?:\.js|js)?\b"],
    "Angular": [r"\bangular\b"],
    "Svelte": [r"\bsvelte\b"],
    "Django": [r"\bdjango\b"],
    "Flask": [r"\bflask\b"],
    "FastAPI": [r"\bfastapi\b"],
    "Spring": [r"\bspring\b"],
    "SQL": [r"\bsql\b"],
    "PostgreSQL": [r"\bpostgres(?:ql)?\b"],
    "MySQL": [r"\bmysql\b"],
    "SQLite": [r"\bsqlite\b"],
    "MongoDB": [r"\bmongo(?:db)?\b"],
    "Redis": [r"\bredis\b"],
    "Elasticsearch": [r"\belastic(?:search)?\b"],
    "RabbitMQ": [r"\brabbitmq\b"],
    "Kafka": [r"\bkafka\b"],
    "GraphQL": [r"\bgraphql\b"],
    "REST": [r"\brest(?:ful)?\b"],
    "gRPC": [r"\bgrpc\b"],
    "HTML": [r"\bhtml?\b"],
    "CSS": [r"\bcss\b"],
    "Tailwind": [r"\btailwind\b"],
    "Sass": [r"\bsass\b|\bscss\b"],
    "Git": [r"\bgit\b"],
    "Linux": [r"\blinux\b"],
    "Docker": [r"\bdocker\b"],
    "Kubernetes": [r"\bkubernetes\b|\bk8s\b"],
    "AWS": [r"\baws\b|amazon web services"],
    "Azure": [r"\bazure\b"],
    "GCP": [r"\bgcp\b|\bgoogle cloud\b"],
    "CI/CD": [r"\bci/?cd\b", r"continuous integration", r"continuous delivery"],
    "Terraform": [r"\bterraform\b"],
    "Ansible": [r"\bansible\b"],
    "Pandas": [r"\bpandas\b"],
    "NumPy": [r"\bnumpy\b"],
    "Scikit-learn": [r"\bscikit[- ]?learn\b|\bsklearn\b"],
    "PyTorch": [r"\bpytorch\b"],
    "TensorFlow": [r"\btensorflow\b"],
    "ASP.NET": [r"\basp\.?net(?:\s*core)?\b"],
    "SQL Server": [r"\bsql\s*server\b", r"\bmssql\b"],
    "GitHub": [r"\bgithub\b"],
    "Bash": [r"\bbash\b"],
    "Shell": [r"\bshell\b", r"\bsh\b"],
    "PowerShell": [r"\bpowershell\b", r"\bps\b"],
    "VS Code": [r"\bvs\s*code\b", r"\bvisual\s+studio\s+code\b"],
    "Visual Studio": [r"\bvisual\s+studio\b"],
    "IIS": [r"\biis\b"],
    "Tomcat": [r"\btomcat\b"],
    "React Native": [r"\breact\s+native\b"],
    "Express": [r"\bexpress(?:\.js)?\b"],
    "SBERT": [r"\bsbert\b"],
    "NLP": [r"\bnlp\b"],
}

# very small soft-skills set to ignore (only removes when clearly isolated)
_SOFT_SKILLS_IGNORE = {
    "communication",
    "teamwork",
    "leadership",
    "problem solving",
    "time management",
    "adaptability",
    "collaboration",
    "customer service",
    "work ethic",
    "creativity",
}

_SKILL_PATTERNS = [
    (canon, re.compile("|".join(frags), re.I)) for canon, frags in _SKILL_CANON.items()
]

SKILLS_HEAD = re.compile(
    r"^(skills?|technical skills?|technologies|tools|tooling|"
    r"tech(?:nical)?(?:\s+stack)?|stack|"
    r"proficiencies|expertise|core (?:skills|competencies)|competenc(?:y|ies)|"
    r"programming languages?|frameworks?(?:\s*&\s*| and )?libraries|frameworks|libraries|"
    r"software|platforms|databases)\b[:\-–—]?",
    re.I,
)
NEXT_SECTION_HEAD = re.compile(
    r"^(experience|work (?:history|experience)|employment|projects?|education|languages?|certifications?)\b",
    re.I,
)


def norm(s: str) -> str:
    return re.sub(r"\s+", " ", (s or "").strip())


def _looks_like_location(s: str) -> bool:
    s = norm(s)
    if not s:
        return False
    # Common "City, State/Province" pattern or contains known location tokens
    if re.match(r"^[A-Za-z .'\-]+,\s*[A-Za-z .'\-]+$", s):
        return True
    return bool(LOCATION_HINT.search(s))


def parse_date_range(s: str):
    """
    Handles (English only):
      - '2008 – Present'
      - '2006 – 2007'
      - 'Jun 2006 – Sep 2006'
      - 'June – Sept 2006'   (borrow year from the other side)
      - '06/2006 – 09/2006'
    """
    txt = (s or "").strip()

    # 1) Try the existing broad regex first (Month Year | Year | mm/yyyy)
    m = DATE_RE.search(txt)

    def to_ym(tok: str):
        if not tok:
            return None
        if re.fullmatch(PRESENT, tok, re.I):
            return "Present"
        if re.fullmatch(YEAR, tok):
            return f"{tok}-01"
        mm = re.match(r"(0?[1-9]|1[0-2])[-/\.]([0-9]{4})", tok)
        if mm:
            return f"{mm.group(2)}-{int(mm.group(1)):02d}"
        mn, yr = _find_month(tok), _find_year(tok)
        if mn and yr:
            return f"{yr}-{mn:02d}"
        return None

    if m:
        start_tok, end_tok = m.group("start"), m.group("end")
        s_norm = to_ym(start_tok)
        e_norm = (
            "Present" if re.fullmatch(PRESENT, end_tok or "", re.I) else to_ym(end_tok)
        )
    else:
        # 2) Fallback for 'June – Sept 2006' etc.
        s_norm = e_norm = None
        left = right = None
        for sep in [" – ", " — ", " - ", "–", "—", "-", " to "]:
            if sep in txt:
                left, right = txt.split(sep, 1)
                left, right = left.strip(), right.strip()
                break
        if left is None:
            return None, None, None

        ly, lm = _find_year(left), _find_month(left)
        ry, rm = _find_year(right), _find_month(right)
        right_present = bool(re.fullmatch(PRESENT, right, re.I))

        # borrow year from the other side when only one side has it
        if lm and not ly and ry is not None:
            ly = ry
        if rm and not ry and ly is not None and not right_present:
            ry = ly

        if ly and lm:
            s_norm = f"{ly}-{lm:02d}"
        elif ly:
            s_norm = f"{ly}-01"

        if right_present:
            e_norm = "Present"
        elif ry and rm:
            e_norm = f"{ry}-{rm:02d}"
        elif ry:
            e_norm = f"{ry}-01"

    # duration (inclusive) when both YYYY-MM present
    months = None
    try:
        if s_norm and e_norm and e_norm != "Present":
            ys, ms = map(int, s_norm.split("-"))
            ye, me = map(int, e_norm.split("-"))
            months = (ye - ys) * 12 + (me - ms) + 1
    except Exception:
        months = None

    return s_norm, e_norm, months


def extract_contacts(text: str) -> dict:
    emails = EMAIL.findall(text) or []
    links = list(dict.fromkeys(LINK.findall(text)))[:5]
    phone = None
    for m in phonenumbers.PhoneNumberMatcher(text, "CA"):
        phone = phonenumbers.format_number(
            m.number, phonenumbers.PhoneNumberFormat.INTERNATIONAL
        )
        break
    # naive name guess: first line with 2-4 TitleCased tokens
    name = ""
    for ln in text.splitlines()[:12]:
        s = norm(ln)
        if not s or len(s) > 60:
            continue
        if any(ch.isdigit() for ch in s):
            continue
        toks = [t for t in s.split() if re.match(r"^[A-Z][a-zA-Z-]+$", t)]
        if 2 <= len(toks) <= 4:
            name = s
            break
    return {
        "email": emails[0] if emails else "",
        "phone": phone or "",
        "links": links,
        "name": name,
    }


def _looks_like_title(s: str) -> bool:
    s = norm(s)
    if not s or s.endswith("."):
        return False
    if _looks_like_location(s):  # <-- add this guard
        return False
    if TITLE_HINT.search(s):
        return True
    toks = [t for t in s.split() if t.isalpha()]
    if not toks:
        return False
    caps = sum(1 for t in toks if t[0].isupper() and not t.isupper())
    return caps / len(toks) >= 0.6 and len(toks) <= 7


VERB_HINT = re.compile(
    r"\b(built|designed|developed|managed|led|mentored|supported|created|owned|implemented|improved|analyzed|wrote|drove|delivered)\b",
    re.I,
)


def _looks_like_company(s: str) -> bool:
    s = norm(s)
    if not s or s.lower().startswith(("http://", "https://", "www.")):
        return False
    if VERB_HINT.search(s):
        return False
    if COMPANY_SUFFIX.search(s):
        return True
    toks = [t for t in s.split() if t.isalpha()]
    if 2 <= len(toks) <= 6:
        caps = sum(1 for t in toks if t[0].isupper() and not t.isupper())
        if caps >= 2 and len(s) <= 48:
            return True
    return False


def _guess_title_company_from_buffer(buf: list[str]) -> tuple[str, str]:
    window = [norm(x) for x in buf if norm(x)][-6:]
    title, company = "", ""
    for i in range(len(window) - 1, -1, -1):
        if _looks_like_company(window[i]):
            company = window[i]
            for j in range(i - 1, -1, -1):
                if _looks_like_title(window[j]):
                    title = window[j]
                    break
            break
    if not title:
        for i in range(len(window) - 1, -1, -1):
            if _looks_like_title(window[i]):
                title = window[i]
                break
    if not company:
        for i in range(len(window) - 1, -1, -1):
            if _looks_like_company(window[i]):
                company = window[i]
                break
    return title, company


def fallback_experience(text_or_lines) -> list[dict]:
    lines = [
        norm(l)
        for l in (
            text_or_lines
            if isinstance(text_or_lines, list)
            else (text_or_lines or "").splitlines()
        )
        if norm(l)
    ]
    items, i, n = [], 0, len(lines)

    def gather_desc(start_idx: int):
        buf, j = [], start_idx
        while j < n:
            s = lines[j]
            if DATE_RE.search(s):
                break
            if _looks_like_title(s) or _looks_like_company(s):
                break
            if len(s) > 110:
                break
            buf.append(BULLET.sub("", s))
            j += 1
        return ("\n".join(buf).strip(), j)

    while i < n:
        line = lines[i]
        if not DATE_RE.search(line):
            i += 1
            continue

        start, end, months = parse_date_range(line)
        title, company, forward_used = "", "", False

        # Prefer forward look:
        if i + 1 < n:
            t1, c1 = _split_title_company_forward(lines[i + 1])
            if t1 or c1:
                title, company, forward_used = t1, c1, True
            elif _looks_like_title(lines[i + 1]):
                title = lines[i + 1]
                forward_used = True
                if i + 2 < n and _looks_like_company(lines[i + 2]):
                    company = lines[i + 2]

        # Fallback: look behind
        if not title and not company:
            ctx = lines[max(0, i - 5) : i]
            title, company = _guess_title_company_from_buffer(ctx)

        # Description starts after any forward-used line(s)
        desc_start = i + (2 if forward_used else 1)
        desc, stop = gather_desc(desc_start)

        if title or company or desc:
            items.append(
                {
                    "title": title,
                    "company": company,
                    "location": "",
                    "dates": {"start": start, "end": end, "months": months},
                    "bullets": [b for b in (desc.split("\n") if desc else []) if b],
                    "technologies": [],
                    "confidence": 0.6 if (title or company) else 0.55,
                }
            )
        i = max(i + 1, stop)

    # dedupe
    seen, uniq = set(), []
    for it in items:
        key = (
            it["company"].lower(),
            it["title"].lower(),
            it["dates"]["start"],
            it["dates"]["end"],
        )
        if key not in seen:
            seen.add(key)
            uniq.append(it)
    return uniq


def skills_text(lines: list[str]) -> str:
    return ", ".join(extract_skills(lines))


def _split_school_location(s: str) -> tuple[str, str]:
    """Very light split: 'LaSalle College, Montreal, QC' -> ('LaSalle College','Montreal, QC')"""
    s = norm(s)
    if "," in s:
        left, right = s.split(",", 1)
        return left.strip(), right.strip()
    return s, ""


def _looks_like_school_line(s: str) -> bool:
    s = norm(s)
    # Require an explicit school keyword to avoid job titles being misread
    if SCHOOL_SUFFIX.search(s):
        return True
    # Allow common high-school patterns explicitly
    if re.search(r"\b(high school|secondary school)\b", s, re.I):
        return True
    return False


def _find_year(tok: str):
    m = re.search(r"\b(19|20)\d{2}\b", tok or "")
    return int(m.group(0)) if m else None


def _find_month(tok: str):
    t = (tok or "").lower()
    t = re.sub(r"[:;.,]+$", "", t)
    for k, v in MONTH_MAP.items():
        if re.search(rf"\b{k}\b", t):
            return v
    return None


_AT_SPLIT = re.compile(r"\s+(?:at|@)\s+", re.I)


def _split_title_company_forward(s: str) -> tuple[str, str]:
    """
    'International Transfer Officer at Friebkla Corporation, France'
    -> ('International Transfer Officer','Friebkla Corporation, France')
    """
    s = norm(s)
    m = _AT_SPLIT.search(s)
    if not m:
        return "", ""
    return s[: m.start()].strip(" -•:·—"), s[m.end() :].strip(" -•:·—")


def _parse_degree_and_field(s: str) -> tuple[str, str]:
    """
    'Diploma of College Studies DEC – Computer Science' -> ('Diploma of College Studies DEC','Computer Science')
    'High School Diploma' -> ('High School Diploma','')
    """
    s = norm(s)
    # strip any trailing date range first
    m = DATE_RE.search(s)
    if m:
        s = norm(s[: m.start()] + " " + s[m.end() :])
    parts = re.split(r"\s(?:–|—|-)\s", s, maxsplit=1)
    if len(parts) == 2:
        deg, fld = parts[0].strip(), parts[1].strip()
    else:
        deg, fld = s, ""
    return deg, fld


def fallback_education(text_or_lines) -> list[dict]:
    """
    Parse common EDUCATION layouts:

      DEGREE – FIELD
      SCHOOL, LOCATION
      YYYY-MM – Present

    Also merges cases where the degree is on one line and the school/dates
    are on the next lines, so we emit *one* item per education.
    """
    lines = [
        norm(l)
        for l in (
            text_or_lines
            if isinstance(text_or_lines, list)
            else (text_or_lines or "").splitlines()
        )
        if norm(l)
    ]

    items, i, n = [], 0, len(lines)

    while i < n:
        line = lines[i]

        # Candidate header if it has a degree keyword OR a date range
        has_deg = bool(DEGREE_HINT.search(line))
        s_start, s_end, months = parse_date_range(line)

        if not (has_deg or (s_start or s_end)):
            i += 1
            continue

        degree, field = _parse_degree_and_field(line)
        school, location = "", ""

        # ---- Look ahead up to 3 lines to capture school and/or dates
        j = i + 1
        while j < n and j <= i + 3:
            cand = lines[j]

            # If we haven't captured the school yet, try to pick it up
            if not school and _looks_like_school_line(cand):
                school, location = _split_school_location(cand)
                j += 1
                continue

            # If we don't have dates yet, try to read a date line
            if not (s_start or s_end):
                s2, e2, m2 = parse_date_range(cand)
                if s2 or e2:
                    s_start, s_end, months = s2, e2, m2
                    j += 1
                    continue

            # Stop early if another education header starts
            if DEGREE_HINT.search(cand):
                break

            j += 1

        items.append(
            {
                "degree": degree,
                "field": field,
                "school": school,
                "location": location,
                "dates": {"start": s_start, "end": s_end, "months": months},
                "gpa": None,
            }
        )

        # Skip over anything we consumed
        i = max(i + 1, j)

    # ---- Merge adjacent partial items (degree-only + school/date-only)
    merged = []
    k = 0
    while k < len(items):
        cur = items[k]
        if k + 1 < len(items):
            nxt = items[k + 1]
            # cur has degree/field but no school; nxt has school/dates but no degree → merge
            cond1 = (cur["degree"] and not cur["school"]) and (
                not nxt["degree"] and nxt["school"]
            )
            # or the reverse ordering
            cond2 = (nxt["degree"] and not nxt["school"]) and (
                not cur["degree"] and cur["school"]
            )
            if cond1 or cond2:
                a, b = (cur, nxt) if cond1 else (nxt, cur)
                merged.append(
                    {
                        "degree": a["degree"] or b["degree"],
                        "field": a["field"] or b["field"],
                        "school": b["school"] or a["school"],
                        "location": b["location"] or a["location"],
                        "dates": {
                            "start": (a["dates"]["start"] or b["dates"]["start"]),
                            "end": (a["dates"]["end"] or b["dates"]["end"]),
                            "months": (a["dates"]["months"] or b["dates"]["months"]),
                        },
                        "gpa": a.get("gpa") or b.get("gpa"),
                    }
                )
                k += 2
                continue
        merged.append(cur)
        k += 1

    return merged


def _clean_skill_token(s: str) -> str:
    # strip bullets and brackets, keep tech punctuation like + # . -
    s = BULLET.sub("", s or "")
    s = re.sub(r"[\(\)\[\]\{\}]", " ", s)
    s = re.sub(r"\b(version|v?\d+(\.\d+){0,2})\b", " ", s, flags=re.I)
    s = re.sub(
        r"\b(and|with|using|experience in|proficient in|familiar with)\b",
        " ",
        s,
        flags=re.I,
    )
    return norm(s)


def _split_on_separators(blob: str) -> list[str]:
    # split on commas, semicolons, pipes, slashes and bullets
    parts = re.split(r"[,;/|•·●◦•\u2022]+", blob)
    out = []
    for p in parts:
        p = _clean_skill_token(p)
        if p:
            # also split "X and Y" occasionally
            subparts = re.split(r"\sand\s", p, flags=re.I)
            out.extend(norm(sp) for sp in subparts if norm(sp))
    return out


def extract_skills(lines: list[str]) -> list[str]:
    """
    English-only skills extractor from the SKILLS section.
    Returns a de-duplicated, order-preserving list of canonical technical skills.
    """
    # 1) Keep only the SKILLS block (stop on dates/long sentences/other sections)
    buf = []
    for l in lines or []:
        s = norm(l)
        if not s:
            continue
        if DATE_RE.search(s):  # skills lines usually don't have date ranges
            break
        if re.search(
            r"\b(education|experience|projects?|languages?|certifications?)\b", s, re.I
        ):
            break
        if len(s) > 100 and re.search(
            r"\b(built|designed|developed|managed|worked|implemented|created)\b",
            s,
            re.I,
        ):
            break
        buf.append(s)

    # 2) Tokenize on separators
    tokens = []
    for line in buf:
        tokens.extend(_split_on_separators(line))

    # 3) Canonicalize against our lexicon
    found: list[str] = []
    seen = set()
    for tok in tokens:
        # ignore obvious soft-skill singletons
        low = tok.lower()
        if low in _SOFT_SKILLS_IGNORE:
            continue

        added = False
        for canon, rx in _SKILL_PATTERNS:
            if rx.search(tok):
                if canon not in seen:
                    seen.add(canon)
                    found.append(canon)
                added = True
                break
        if added:
            continue

        # 4) If it looks like a legit tech token not in lexicon, keep the cleaned token
        # heuristics: short (<=3 words), not a sentence, has letters/numbers
        if 1 <= len(tok.split()) <= 3 and not tok.endswith("."):
            # normalize common variants
            tok = re.sub(
                r"\s+(framework|library|stack|lang(uage)?)\b", "", tok, flags=re.I
            ).strip()
            if tok and tok.lower() not in seen:
                seen.add(tok.lower())
                # preserve capitalization for things like "Git", "Linux", "Bash"
                found.append(tok)

    return found[:100]  # cap to keep UI tidy


def extract_skills_from_text(text: str) -> list[str]:
    lines = [norm(l) for l in (text or "").splitlines() if norm(l)]
    i = 0
    while i < len(lines):
        m = SKILLS_HEAD.match(lines[i])
        if m:
            buf = []
            tail = lines[i][m.end() :].strip(" :–—-")
            if tail:
                buf.append(tail)
            j = i + 1
            while j < len(lines):
                s = lines[j]
                if NEXT_SECTION_HEAD.match(s):
                    break
                if len(s) > 140 and re.search(
                    r"\b(built|designed|developed|managed|implemented|created)\b",
                    s,
                    re.I,
                ):
                    break
                buf.append(s)
                j += 1
            return extract_skills(buf)
        i += 1
    return []


================================================================================
// Path: ats_parser/sections.py
================================================================================

import re


def split_sections(text: str) -> dict[str, list[str]]:
    SECTION_PATTERNS = {
        "SUMMARY": re.compile(
            r"^(summary|professional summary|profile)\b[:\-–—]?", re.I
        ),
        "EXPERIENCE": re.compile(
            r"^(experience|work (?:history|experience)|employment|professional experience|projects?)\b[:\-–—]?",
            re.I,
        ),
        "EDUCATION": re.compile(
            r"^(education|academic background|studies)\b[:\-–—]?", re.I
        ),
        "SKILLS": re.compile(
            r"^(skills?|technical skills?|technologies|tools|tooling|"
            r"tech(?:nical)?(?:\s+stack)?|stack|"
            r"proficiencies|expertise|core (?:skills|competencies)|competenc(?:y|ies)|"
            r"programming languages?|frameworks?(?:\s*&\s*| and )?libraries|frameworks|libraries|"
            r"software|platforms|databases)\b[:\-–—]?",
            re.I,
        ),
        "CERTS": re.compile(r"^(certifications?|licenses?)\b[:\-–—]?", re.I),
        "LANGUAGES": re.compile(r"^(languages?)\b[:\-–—]?", re.I),
        "PROJECTS": re.compile(
            r"^(projects|selected projects|personal projects)\b[:\-–—]?", re.I
        ),
    }
    lines = [l.rstrip() for l in text.splitlines()]
    cur = None
    out = {k: [] for k in SECTION_PATTERNS.keys()}
    out.setdefault("OTHER", [])
    for ln in lines:
        s = re.sub(r"\s+", " ", (ln or "").strip())
        if not s:
            continue
        switched = False
        for key, rx in SECTION_PATTERNS.items():
            if rx.match(s):
                m = rx.match(s)
                cur = key
                switched = True
                # NEW: keep anything after the heading, e.g. "Skills: C#, Java"
                tail = s[m.end():].strip(" :–—-")
                if tail:
                    out[cur].append(tail)
                break
        if not switched:
            (out[cur] if cur else out["OTHER"]).append(s)
    return out


================================================================================
// Path: templates/_flash.html
================================================================================

{% if get_flashed_messages(with_categories=true) %}
<style>
    .flash {
        border-left: 4px solid;
    }

    .flash.success {
        border-left-color: #10b981;
    }

    .flash.warn {
        border-left-color: #f59e0b;
    }

    .flash.info {
        border-left-color: #3b82f6;
    }

    .flash.error {
        border-left-color: #ef4444;
    }
</style>

<div style="margin:10px 0">
    {% for cat, msg in get_flashed_messages(with_categories=true) %}
    {% set cls = 'success' if cat=='success' else 'warn' if cat=='warn' else 'info' if cat=='info' else 'error' %}
    <div class="card flash {{ cls }}">{{ msg }}</div>
    {% endfor %}
</div>
{% endif %}

================================================================================
// Path: templates/_theme.html
================================================================================

<style>
    :root {
        --bg: #0a0f1d;
        --bg-soft: #0b1224;
        --surface: #0f172a;
        --surface-2: #111b31;
        --border: #1e293b;
        --text: #e5e7eb;
        --muted: #94a3b8;
        --primary: #3b82f6;
        /* blue */
        --primary-2: #60a5fa;
        --green: #10b981;
        --amber: #f59e0b;
        --red: #ef4444;
        --ring: rgba(59, 130, 246, .45);
        --shadow: 0 10px 30px rgba(0, 0, 0, .35);
    }

    * {
        box-sizing: border-box
    }

    html,
    body {
        height: 100%
    }

    body {
        margin: 0;
        background:
            radial-gradient(1200px 600px at 20% -10%, rgba(59, 130, 246, .12), transparent 60%),
            radial-gradient(1000px 500px at 120% 10%, rgba(16, 185, 129, .10), transparent 60%),
            var(--bg);
        color: var(--text);
        background-repeat: no-repeat, no-repeat, no-repeat, no-repeat, no-repeat;
        background-attachment: fixed, fixed, fixed, fixed, fixed;
        font: 15px/1.5 Inter, system-ui, -apple-system, Segoe UI, Roboto, sans-serif;
    }

    /* Header + Nav */
    header {
        padding: 22px 0;
        background:
            linear-gradient(180deg, rgba(16, 24, 40, .6), rgba(16, 24, 40, 0)),
            linear-gradient(90deg, rgba(59, 130, 246, .18), rgba(59, 130, 246, 0) 40%, rgba(16, 185, 129, .18));
        border-bottom: 1px solid var(--border);
        backdrop-filter: saturate(130%) blur(6px);
    }

    header .container {
        max-width: 1100px;
        margin: 0 auto;
        padding: 0 16px;
        display: flex;
        align-items: center;
        justify-content: space-between
    }

    header h1 {
        margin: 0;
        font-size: 18px;
        letter-spacing: .2px
    }

    nav .btn {
        margin-right: 8px
    }

    /* Layout */
    main {
        max-width: 1100px;
        margin: 24px auto;
        padding: 0 16px
    }

    /* Card */
    .card {
        background: linear-gradient(180deg, var(--surface), var(--surface-2));
        border: 1px solid var(--border);
        border-radius: 14px;
        padding: 18px;
        margin: 16px 0;
        box-shadow: var(--shadow);
        transition: transform .15s ease, box-shadow .15s ease, border-color .15s ease;
    }

    .card:hover {
        transform: translateY(-1px);
        border-color: #2a3a55
    }

    /* Upload bar */
    .upload {
        display: flex;
        gap: 12px;
        align-items: center;
        background: var(--surface);
        border: 1px solid var(--border);
        border-radius: 12px;
        padding: 14px 16px;
    }

    .upload input[type=file] {
        flex: 1;
        color: var(--muted)
    }

    .upload button {
        min-width: 160px
    }

    /* Forms */
    label {
        display: block;
        font-size: 12px;
        color: var(--muted);
        margin: 0 0 6px 2px
    }

    input,
    textarea {
        width: 100%;
        padding: 10px 12px;
        border: 1px solid var(--border);
        border-radius: 10px;
        background: #0b1120;
        color: var(--text);
        outline: none;
        transition: border-color .15s ease, box-shadow .15s ease, background .15s;
    }

    input:focus,
    textarea:focus {
        border-color: var(--primary);
        box-shadow: 0 0 0 4px var(--ring);
        background: #0c1426;
    }

    textarea {
        min-height: 96px;
        resize: vertical
    }

    /* Buttons */
    .btn {
        --btn-bg: #0b1120;
        --btn-bd: var(--border);
        --btn-fg: var(--text);
        display: inline-flex;
        align-items: center;
        justify-content: center;
        gap: 8px;
        padding: 9px 14px;
        border-radius: 10px;
        border: 1px solid var(--btn-bd);
        background: var(--btn-bg);
        color: var(--btn-fg);
        cursor: pointer;
        text-decoration: none;
        transition: transform .12s ease, background .15s, border-color .15s, box-shadow .15s;
    }

    .btn:hover {
        transform: translateY(-1px);
        border-color: #2b3b57
    }

    .btn:active {
        transform: translateY(0)
    }

    .btn.primary {
        --btn-bg: linear-gradient(180deg, var(--primary-2), var(--primary));
        --btn-bd: transparent;
        --btn-fg: #fff;
        box-shadow: 0 6px 18px rgba(59, 130, 246, .25);
    }

    .btn.destructive {
        --btn-bg: #1b0e12;
        --btn-bd: #402227;
        --btn-fg: #fecaca;
    }

    .btn.ghost {
        --btn-bg: transparent;
        --btn-bd: var(--border);
        --btn-fg: var(--text);
    }

    /* Badges / Chips */
    .badge {
        display: inline-block;
        padding: 4px 10px;
        border-radius: 999px;
        background: #16253f;
        color: #b6d4ff;
        border: 1px solid var(--border);
        font-size: 12px
    }

    /* Grid helpers already in your HTML – keep them */
    .grid {
        display: grid;
        grid-template-columns: repeat(12, 1fr);
        gap: 12px
    }

    .col-12 {
        grid-column: span 12
    }

    .col-6 {
        grid-column: span 6
    }

    .col-4 {
        grid-column: span 4
    }

    .col-3 {
        grid-column: span 3
    }

    /* Tables (admin) */
    table {
        width: 100%;
        border-collapse: separate;
        border-spacing: 0;
        border: 1px solid var(--border);
        border-radius: 12px;
        overflow: hidden
    }

    thead th {
        font-weight: 600;
        font-size: 12px;
        color: var(--muted);
        background: #0c1426
    }

    th,
    td {
        padding: 10px 12px;
        border-bottom: 1px solid var(--border)
    }

    tbody tr:nth-child(odd) {
        background: #0b1224
    }

    tbody tr:hover {
        background: #0f1a33
    }

    td .btn {
        padding: 6px 10px
    }

    /* Flash banners (uses your existing partial) */
    .flash {
        border-left: 4px solid;
        background: #0d1428;
        padding: 10px 14px;
        border-radius: 10px;
        margin: 8px 0
    }

    .flash.success {
        border-left-color: var(--green);
        background: rgba(16, 185, 129, .12)
    }

    .flash.warn {
        border-left-color: var(--amber);
        background: rgba(245, 158, 11, .12)
    }

    .flash.info {
        border-left-color: var(--primary);
        background: rgba(59, 130, 246, .12)
    }

    .flash.error {
        border-left-color: var(--red);
        background: rgba(239, 68, 68, .12)
    }

    /* Section dividers */
    .section {
        margin-top: 16px;
        padding-top: 16px;
        border-top: 1px dashed var(--border)
    }

    /* Utility */
    .container {
        max-width: 1100px;
        margin: 0 auto;
        padding: 0 16px
    }

    .muted {
        color: var(--muted)
    }
</style>

================================================================================
// Path: templates/admin_candidates.html
================================================================================

<!doctype html>
<html>

<head>
    <meta charset="utf-8">
    {% include "_theme.html" %}
    <title>All Candidates</title>
</head>

<body style="font-family:Inter,system-ui;background:#0b0f1a;color:#e5e7eb">
    <main style="max-width:1100px;margin:40px auto;padding:16px">
        {% include "_flash.html" %}
        <div class="card">
            <h2>All Candidates</h2>
            <table style="width:100%;border-collapse:collapse">
                <thead>
                    <tr>
                        <th style="text-align:left;padding:8px;border-bottom:1px solid #1f2937">ID</th>
                        <th style="text-align:left;padding:8px;border-bottom:1px solid #1f2937">Name</th>
                        <th style="text-align:left;padding:8px;border-bottom:1px solid #1f2937">Email</th>
                        <th style="text-align:left;padding:8px;border-bottom:1px solid #1f2937">Phone</th>
                        <th></th>
                    </tr>
                </thead>
                <tbody>
                    {% for r in rows %}
                    <tr>
                        <td style="padding:8px;border-bottom:1px solid #1f2937">{{ r[0] }}</td>
                        <td style="padding:8px;border-bottom:1px solid #1f2937">{{ r[1] }}</td>
                        <td style="padding:8px;border-bottom:1px solid #1f2937">{{ r[2] }}</td>
                        <td style="padding:8px;border-bottom:1px solid #1f2937">{{ r[3] }}</td>
                        <td style="padding:8px;border-bottom:1px solid #1f2937">
                            <form method="post" action="{{ url_for('admin_delete_candidate', cand_id=r[0]) }}"
                                onsubmit="return confirm('Delete candidate #{{r[0]}}?')">
                                <button class="btn" style="border-color:#ef4444">Delete</button>
                            </form>
                        </td>
                    </tr>
                    {% endfor %}
                </tbody>
            </table>
            <div style="margin-top:12px">
                <a class="btn" href="{{ url_for('index') }}">Back to app</a>
            </div>
        </div>
    </main>
</body>

</html>

================================================================================
// Path: templates/admin_cvs.html
================================================================================

<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <title>All CVs – ATS Scanner</title>
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <style>
        :root {
            --bg: #0b0f1a;
            --card: #0f1422;
            --muted: #9aa3af;
            --accent: #3b82f6;
            --border: #1f2937;
            --text: #e5e7eb;
        }

        body {
            margin: 0;
            font-family: Inter, system-ui, -apple-system, Segoe UI, Roboto, sans-serif;
            background: var(--bg);
            color: var(--text);
        }

        main {
            max-width: 1100px;
            margin: 20px auto;
            padding: 0 16px;
        }

        .card {
            background: var(--card);
            border: 1px solid var(--border);
            border-radius: 14px;
            padding: 18px;
            margin: 16px 0;
        }

        .btn {
            border: 1px solid var(--border);
            background: #0b1120;
            color: var(--text);
            padding: 8px 12px;
            border-radius: 8px;
            text-decoration: none;
        }

        a.download {
            color: #93c5fd;
            text-decoration: none;
        }

        ul {
            list-style: none;
            padding: 0;
            margin: 0;
        }

        li {
            padding: 10px 0;
            border-bottom: 1px solid rgba(255, 255, 255, .03);
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        small {
            color: var(--muted);
        }
    </style>
    {% include "_theme.html" %}
</head>

<body>
    <header style="padding:20px;background:#0a0f1d;border-bottom:1px solid var(--border);">
        <h1 style="margin:0;font-size:20px;">All CVs (PDF)</h1>
    </header>
    <main>
        <nav class="card" style="display:flex;gap:12px;justify-content:space-between;align-items:center;">
            <div>
                <a class="btn" href="/">Home</a>
                <a class="btn" href="/admin">Admin</a>
                <a class="btn" href="{{ url_for('admin_cvs') }}">All CVs</a>
            </div>
            <a class="btn" href="/logout">Log out</a>
        </nav>

        <div class="card">
            {% if items %}
            <ul>
                {% for it in items %}
                <li>
                    <div>
                        <strong>{{ it.display_name }}</strong><br>
                        <small>{{ it.filename }}</small>
                    </div>
                    <a class="btn" href="{{ url_for('admin_download_cv', filename=it.filename) }}">Download</a>
                </li>
                {% endfor %}
            </ul>
            {% else %}
            <p>No CVs uploaded yet.</p>
            {% endif %}
        </div>

    </main>
</body>

</html>

================================================================================
// Path: templates/admin_home.html
================================================================================

<!doctype html>
<html>

<head>
    <meta charset="utf-8">
    <title>Admin</title>
</head>

<body style="font-family:Inter,system-ui;background:#0b0f1a;color:#e5e7eb">
    <main style="max-width:900px;margin:40px auto;padding:16px">
        {% include "_flash.html" %}
        <div class="card">
            <h2>Admin</h2>
            <p>Welcome, {{ user.username }}.</p>
            <div style="display:flex;gap:10px">
                <a class="btn" href="{{ url_for('admin_candidates') }}">See all candidates</a>
                <a class="btn" href="{{ url_for('index') }}">Back to app</a>
            </div>
        </div>
    </main>
</body>

</html>

================================================================================
// Path: templates/admin_users.html
================================================================================

<!doctype html>
<html>

<head>
    <meta charset="utf-8">
    <title>Admin — Users</title>
    {% include "_theme.html" %}
</head>

<body>
    <main class="container">
        {% include "_flash.html" %}
        <div class="card">
            <h2>Users</h2>
            <table>
                <thead>
                    <tr>
                        <th>ID</th>
                        <th>Username</th>
                        <th>Active</th>
                        <th>Admin</th>
                        <th>Uploads</th>
                        <th>Actions</th>
                    </tr>
                </thead>
                <tbody>
                    {% for id, username, active, is_admin, uploads in rows %}
                    <tr>
                        <td>{{ id }}</td>
                        <td>{{ username }}</td>
                        <td>{{ 'Yes' if active else 'No' }}</td>
                        <td>{{ 'Yes' if is_admin else 'No' }}</td>
                        <td>{{ uploads }}</td>
                        <td style="display:flex; gap:.5rem; flex-wrap:wrap">
                            {% if active %}
                            <form method="post" action="{{ url_for('deactivate_user', uid=id) }}">
                                <button class="btn warn" type="submit">Deactivate</button>
                            </form>
                            {% else %}
                            <form method="post" action="{{ url_for('activate_user', uid=id) }}">
                                <button class="btn" type="submit">Activate</button>
                            </form>
                            {% endif %}
                            <form method="post" action="{{ url_for('admin_reset_user', uid=id) }}">
                                <button class="btn" type="submit">Reset PW</button>
                            </form>
                        </td>
                    </tr>
                    {% endfor %}
                </tbody>
            </table>
            <div style="margin-top:12px">
                <a class="btn" href="{{ url_for('index') }}">Back to app</a>
            </div>
        </div>
    </main>
</body>

</html>

================================================================================
// Path: templates/auth_login.html
================================================================================

<!doctype html>
<html>

<head>
    <meta charset="utf-8">
    {% include "_theme.html" %}
    <title>Login</title>
</head>

<body style="font-family:Inter,system-ui;background:#0b0f1a;color:#e5e7eb">
    <main style="max-width:420px;margin:40px auto;padding:16px">
        {% include "_flash.html" %}
        <div class="card">
            <h2>Log in</h2>
            <form method="post" action="{{ url_for('login', next=next) }}">
                <label>Username</label><input name="username" required>
                <label>Password</label><input type="password" name="password" required>
                <div style="margin-top:12px;display:flex;gap:8px">
                    <button class="btn primary">Log in</button>
                    <a class="btn" href="{{ url_for('signup') }}">Create account</a>
                    <a class="btn" href="{{ url_for('reset_request') }}">Reset password</a>
                </div>
            </form>
        </div>
    </main>
</body>

</html>

================================================================================
// Path: templates/auth_reset_request.html
================================================================================

<!doctype html>
<html>

<head>
    <meta charset="utf-8">
    {% include "_theme.html" %}
    <title>Reset password</title>
</head>

<body style="font-family:Inter,system-ui;background:#0b0f1a;color:#e5e7eb">
    <main style="max-width:420px;margin:40px auto;padding:16px">
        {% include "_flash.html" %}
        <div class="card">
            <h2>Password reset</h2>
            <p class="muted">Enter your username. A reset token will be generated (demo flow).</p>
            <form method="post">
                <label>Username</label><input name="username" required>
                <div style="margin-top:12px;display:flex;gap:8px">
                    <button class="btn primary">Generate token</button>
                    <a class="btn" href="{{ url_for('login') }}">Back to login</a>
                </div>
            </form>
        </div>
    </main>
</body>

</html>

================================================================================
// Path: templates/auth_reset_set.html
================================================================================

<!doctype html>
<html>

<head>
    <meta charset="utf-8">
    {% include "_theme.html" %}
    <title>Set new password</title>
</head>

<body style="font-family:Inter,system-ui;background:#0b0f1a;color:#e5e7eb">
    <main style="max-width:420px;margin:40px auto;padding:16px">
        {% include "_flash.html" %}
        <div class="card">
            <h2>Choose a new password</h2>
            <form method="post">
                <label>New password</label><input type="password" name="password" required>
                <div style="margin-top:12px;display:flex;gap:8px">
                    <button class="btn primary">Update</button>
                    <a class="btn" href="{{ url_for('login') }}">Cancel</a>
                </div>
            </form>
        </div>
    </main>
</body>

</html>

================================================================================
// Path: templates/auth_signup.html
================================================================================

<!doctype html>
<html>

<head>
    <meta charset="utf-8">
    {% include "_theme.html" %}
    <title>Sign up</title>
</head>

<body style="font-family:Inter,system-ui;background:#0b0f1a;color:#e5e7eb">
    <main style="max-width:420px;margin:40px auto;padding:16px">
        {% include "_flash.html" %}
        <div class="card">
            <h2>Create account</h2>
            <form method="post">
                <label>Username</label><input name="username" required>
                <label>Password</label><input type="password" name="password" required>
                <div style="margin-top:12px;display:flex;gap:8px">
                    <button class="btn primary">Create</button>
                    <a class="btn" href="{{ url_for('login') }}">Back to login</a>
                </div>
            </form>
        </div>
    </main>
</body>

</html>

================================================================================
// Path: templates/index.html
================================================================================

<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <title>ATS Scanner</title>
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <style>
    :root {
      --bg: #0b0f1a;
      --card: #0f1422;
      --muted: #9aa3af;
      --accent: #3b82f6;
      --border: #1f2937;
      --text: #e5e7eb;
    }

    * {
      box-sizing: border-box;
    }

    body {
      margin: 0;
      font-family: Inter, system-ui, -apple-system, Segoe UI, Roboto, sans-serif;
      background: var(--bg);
      color: var(--text);
    }

    header {
      padding: 20px;
      background: #0a0f1d;
      border-bottom: 1px solid var(--border);
    }

    header h1 {
      margin: 0;
      font-size: 20px;
    }

    main {
      max-width: 1100px;
      margin: 20px auto;
      padding: 0 16px;
    }

    .upload {
      background: var(--card);
      padding: 16px;
      border-radius: 12px;
      border: 1px solid var(--border);
      display: flex;
      gap: 12px;
      align-items: center;
    }

    .upload input[type=file] {
      flex: 1;
      color: var(--muted);
    }

    .upload button {
      background: var(--accent);
      color: #fff;
      border: none;
      padding: 10px 14px;
      border-radius: 8px;
      cursor: pointer;
    }

    .card {
      background: var(--card);
      border: 1px solid var(--border);
      border-radius: 14px;
      padding: 18px;
      margin: 16px 0;
      box-shadow: 0 2px 10px rgba(0, 0, 0, 0.12);
    }

    .grid {
      display: grid;
      grid-template-columns: repeat(12, 1fr);
      gap: 12px;
    }

    .col-12 {
      grid-column: span 12;
    }

    .col-6 {
      grid-column: span 6;
    }

    .col-4 {
      grid-column: span 4;
    }

    .col-3 {
      grid-column: span 3;
    }

    label {
      font-size: 12px;
      color: var(--muted);
      display: block;
      margin-bottom: 6px;
    }

    input,
    textarea {
      width: 100%;
      padding: 10px;
      border: 1px solid var(--border);
      border-radius: 10px;
      background: #0b1120;
      color: var(--text);
    }

    textarea {
      min-height: 80px;
      resize: vertical;
    }

    .row {
      display: flex;
      gap: 10px;
      align-items: center;
    }

    .badge {
      display: inline-block;
      padding: 4px 10px;
      background: #1f2a44;
      color: #93c5fd;
      border-radius: 999px;
      font-size: 12px;
      margin-right: 6px;
      border: 1px solid var(--border);
    }

    .btn {
      border: 1px solid var(--border);
      background: #0b1120;
      color: var(--text);
      padding: 8px 12px;
      border-radius: 8px;
      cursor: pointer;
    }

    .btn.primary {
      background: var(--accent);
      color: #fff;
      border-color: var(--accent);
    }

    .btn.destructive {
      background: #b91c1c;
      border-color: #b91c1c;
      color: #fff;
    }

    .section {
      margin-top: 16px;
      padding-top: 16px;
      border-top: 1px dashed var(--border);
    }

    .muted {
      color: var(--muted);
    }
  </style>
  {% include "_theme.html" %}
</head>

<body>
  <header>
    <div class="container">
      <h1>ATS Scanner — Structured Resume Parser</h1>
    </div>
  </header>
  <main>
    <nav class="card" style="display:flex; gap:12px; align-items:center; justify-content:space-between;">
      <div>
        <a class="btn" href="/">Home</a>
        {% if user and user.is_admin %}
        <a class="btn" href="/admin">Admin</a>
        <a class="btn" href="{{ url_for('admin_cvs') }}">All CVs</a>
        <a class="btn" href="{{ url_for('admin_users') }}">Admin Users</a>
        {% endif %}
      </div>
      <div>
        <a class="btn" href="/logout">Log out</a>
      </div>
    </nav>

    {% include "_flash.html" %}

    <form class="upload" action="{{ url_for('upload') }}" method="post" enctype="multipart/form-data"
      onsubmit="this.querySelector('button').disabled=true;this.querySelector('button').textContent='Uploading…';">
      <input type="file" name="file" accept=".pdf,.docx" required>
      <button type="submit" class="btn primary">Upload & Parse</button>
    </form>

    {% for c in candidates %}
    {% set cid = c[0] %}
    {% set name = c[1] %}
    {% set first = c[2] or "" %}
    {% set middle = c[3] or "" %}
    {% set last = c[4] or "" %}
    {% set phone = c[5] or "" %}
    {% set email = c[6] or "" %}
    {% set links = (json.loads(c[7] or "[]")) %}
    {% set edu = json.loads(c[8] or "[]") %}
    {% set exp = json.loads(c[9] or "[]") %}
    {% set skills = c[10] or "" %}

    <!-- candidate card -->
    <div class="card" id="card-{{ cid }}">

      <div class="row" style="justify-content:space-between; align-items:center">
        <h2 style="margin:0">{{ name or "Unnamed Candidate" }}</h2>

        <div style="display:flex; gap:8px; align-items:center">
          <!-- show short number -->
          <span class="badge">ID #{{ loop.index }}</span>

          <!-- Delete this CV -->
          <form method="post" action="{{ url_for('delete_cv', cand_id=cid) }}"
            onsubmit="return confirm('Delete this CV?');" style="display:inline">
            <button class="btn destructive" type="submit">Delete CV</button>
          </form>

          <!-- Re-upload this CV -->
          <form method="post" action="{{ url_for('reupload_cv', cand_id=cid) }}" enctype="multipart/form-data"
            style="display:inline-flex; gap:6px; align-items:center">
            <input type="file" name="file" accept=".pdf,.docx" required>
            <button class="btn" type="submit">Re-upload</button>
          </form>

          <!-- Clear inputs in this card (front-end only) 
          <button type="button" class="btn" onclick="clearCard('{{ cid }}')">
            Clear this card
          </button>
          <button type="button" class="btn" onclick="clearAllDescriptions('{{ cid }}')">
            Clear all Role Descriptions
          </button>
          -->
        </div>
      </div>

      <div class="grid section">
        <div class="col-4">
          <label>First Name</label>
          <input id="first-{{cid}}" value="{{ first }}">
        </div>
        <div class="col-4">
          <label>Middle Name</label>
          <input id="middle-{{cid}}" value="{{ middle }}">
        </div>
        <div class="col-4">
          <label>Last Name</label>
          <input id="last-{{cid}}" value="{{ last }}">
        </div>

        <div class="col-6">
          <label>Phone</label>
          <input id="phone-{{cid}}" value="{{ phone }}">
        </div>
        <div class="col-6">
          <label>Email</label>
          <input id="email-{{cid}}" value="{{ email }}">
        </div>

        <div class="col-12">
          <label>Links</label>
          <div id="links-{{cid}}">
            {% if links|length == 0 %}
            <input id="link-{{cid}}-0" value="">
            {% else %}
            {% for u in links %}
            <input id="link-{{cid}}-{{loop.index0}}" value="{{ u }}">
            {% endfor %}
            {% endif %}
          </div>
        </div>
      </div>

      <div class="section">
        <h3>Experience</h3>
        {% if exp|length == 0 %}<p class="muted">No experience parsed.</p>{% endif %}
        {% for e in exp %}
        <div class="grid" style="margin-bottom:12px;" data-exp="{{loop.index0}}">
          <div class="col-4">
            <label>Position</label>
            <input id="exp-{{cid}}-{{loop.index0}}-position" value="{{ e.get('position','') }}">
          </div>
          <div class="col-4">
            <label>Company</label>
            <input id="exp-{{cid}}-{{loop.index0}}-company_name"
              value="{{ e.get('company_name', e.get('company','')) }}">
          </div>
          <div class="col-4">
            <label>Location</label>
            <input id="exp-{{cid}}-{{loop.index0}}-location" value="{{ e.get('location','') }}">
          </div>
          <div class="col-4">
            <label>Start Date</label>
            <input id="exp-{{cid}}-{{loop.index0}}-start_date" value="{{ e.get('start_date','') }}">
          </div>
          <div class="col-4">
            <label>End Date</label>
            <input id="exp-{{cid}}-{{loop.index0}}-end_date" value="{{ e.get('end_date','') }}">
          </div>
          <div class="col-4">
            <label>Duration (months)</label>
            <input id="exp-{{cid}}-{{loop.index0}}-duration_months" value="{{ e.get('duration_months','') }}">
          </div>
          <div class="col-12">
            <div class="row" style="justify-content:space-between; align-items:center">
              <label style="margin:0">Role Description</label>
              <button type="button" class="btn" onclick="clearField('exp-{{cid}}-{{loop.index0}}-description')">
                Clear
              </button>
            </div>
            <textarea id="exp-{{cid}}-{{loop.index0}}-description">{{ e.get('description','') }}</textarea>
          </div>
        </div>
        {% endfor %}
      </div>

      <div class="section">
        <h3>Education</h3>
        {% set edu_list = edu if edu|length > 0 else [
        {'level':'','field':'','school_name':'','location':'','start_year':'','end_year':''} ] %}
        {% for ed in edu_list %}
        <div class="grid" style="margin-bottom:12px;" data-edu="{{loop.index0}}">
          <div class="col-4">
            <label>Level</label>
            <input id="edu-{{cid}}-{{loop.index0}}-level" value="{{ ed.get('level', ed.get('degree','')) }}">
          </div>
          <div class="col-4">
            <label>Field</label>
            <input id="edu-{{cid}}-{{loop.index0}}-field" value="{{ ed.get('field','') }}">
          </div>
          <div class="col-4">
            <label>School</label>
            <input id="edu-{{cid}}-{{loop.index0}}-school_name" value="{{ ed.get('school_name', ed.get('school','')) }}"
              readonly>
          </div>
          <div class="col-6">
            <label>Location</label>
            <input id="edu-{{cid}}-{{loop.index0}}-location" value="{{ ed.get('location','') }}">
          </div>
          <div class="col-3">
            <label>Start Year</label>
            <input id="edu-{{cid}}-{{loop.index0}}-start_year" value="{{ ed.get('start_year','') }}">
          </div>
          <div class="col-3">
            <label>End Year</label>
            <input id="edu-{{cid}}-{{loop.index0}}-end_year" value="{{ ed.get('end_year','') }}">
          </div>
        </div>
        {% endfor %}
      </div>

      <div class="grid section">
        <div class="col-12">
          <div class="row" style="justify-content:space-between; align-items:center">
            <label style="margin:0">Skills (technical; CSV)</label>
            <button type="button" class="btn" onclick="clearField('skills-{{cid}}')">
              Clear
            </button>
          </div>
          <textarea id="skills-{{cid}}">{{ skills }}</textarea>
        </div>

      </div>

    </div>
    <!-- end candidate card -->

    {% endfor %}

    <div class="card" style="display:flex; justify-content:space-between; align-items:center; gap:12px;">
      <form method="post" action="{{ url_for('account_delete') }}"
        onsubmit="return confirm('Delete your account and all uploads?');"
        style="display:flex;gap:8px;align-items:center">
        <input type="password" name="password" placeholder="Confirm password" required>
        <button class="btn">Delete my account</button>
      </form>
      <button type="button" class="btn primary" id="save-all">Save All Changes</button>
    </div>
  </main>

  <script>
    document.addEventListener('DOMContentLoaded', () => {
      document.querySelectorAll('input[readonly], textarea[readonly]')
        .forEach(el => el.removeAttribute('readonly'));
      const btn = document.getElementById('save-all');
      if (btn) btn.addEventListener('click', saveAllCandidates);
    });

    // NEW: clear only text inputs / textareas for this card
    function clearCard(id) {
      document
        .querySelectorAll(`#card-${id} input, #card-${id} textarea`)
        .forEach(el => {
          // don't clear file inputs
          if (el.type === 'file') return;
          el.value = '';
        });
    }

    function collectLinks(cid) {
      const wrap = document.getElementById(`links-${cid}`);
      const arr = [];
      if (!wrap) return arr;
      wrap.querySelectorAll('input[id^="link-"]').forEach(el => {
        const v = (el.value || "").trim();
        if (v) arr.push(v);
      });
      return arr;
    }

    function collectList(prefix, cid, attrNames) {
      const card = document.getElementById(`card-${cid}`);
      const blocks = [];
      if (!card) return blocks;
      card.querySelectorAll(`[data-${prefix}]`).forEach(block => {
        const idx = block.getAttribute(`data-${prefix}`);
        const obj = {};
        attrNames.forEach(name => {
          const el = document.getElementById(`${prefix}-${cid}-${idx}-${name}`);
          obj[name] = el ? el.value : "";
        });
        blocks.push(obj);
      });
      return blocks;
    }

    function collectCandidate(cid) {
      const first = (document.getElementById(`first-${cid}`)?.value || "");
      const middle = (document.getElementById(`middle-${cid}`)?.value || "");
      const last = (document.getElementById(`last-${cid}`)?.value || "");
      const phone = (document.getElementById(`phone-${cid}`)?.value || "");
      const email = (document.getElementById(`email-${cid}`)?.value || "");
      const links = collectLinks(cid);
      const name = [first, middle, last].filter(Boolean).join(' ').trim();

      const experience = collectList('exp', cid, [
        'position', 'company_name', 'location', 'start_date', 'end_date', 'duration_months', 'description'
      ]).map(e => {
        e.duration_months = e.duration_months ? parseInt(e.duration_months, 10) : null;
        e.skills_used_tech = e.skills_used_tech || [];
        e.skills_used_soft = e.skills_used_soft || [];
        return e;
      });

      const education = collectList('edu', cid, [
        'level', 'field', 'school_name', 'location', 'start_year', 'end_year'
      ]);

      const skills = (document.getElementById(`skills-${cid}`)?.value || "");
      const languages = "";

      return {
        name, first_name: first, middle_name: middle, last_name: last,
        phone, email, links, education, experience, skills, languages
      };
    }

    function clearField(id) {
      const el = document.getElementById(id);
      if (el && (el.tagName === 'TEXTAREA' || el.tagName === 'INPUT')) {
        el.value = '';
        el.dispatchEvent(new Event('input'));
      }
    }

    function clearAllDescriptions(cid) {
      document
        .querySelectorAll(`#card-${cid} textarea[id^="exp-${cid}-"][id$="-description"]`)
        .forEach(t => {
          t.value = '';
          t.dispatchEvent(new Event('input'));
        });
    }

    async function saveAllCandidates() {
      const btn = document.getElementById('save-all');
      if (btn) { btn.disabled = true; btn.textContent = 'Saving...'; }
      const cards = document.querySelectorAll('.card[id^="card-"]');
      let ok = 0, fail = 0;

      for (const card of cards) {
        const cid = parseInt(card.id.replace('card-', ''), 10);
        const payload = collectCandidate(cid);
        try {
          const res = await fetch(`/update/${cid}`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify(payload)
          });
          if (res.ok) ok++; else fail++;
        } catch {
          fail++;
        }
      }

      if (btn) {
        btn.disabled = false;
        btn.textContent = 'Save All Changes';
      }
      alert(`Saved ${ok} candidate(s)` + (fail ? `, ${fail} failed` : ''));
    } 
  </script>

</body>

</html>

================================================================================
// Path: tests/test_smoke.py
================================================================================

# tests/test_smoke.py
import importlib
import sys
import types

import pytest


def _import_fresh(module_name: str):
    """Import a module after removing it from sys.modules (so env vars apply)."""
    if module_name in sys.modules:
        del sys.modules[module_name]
    return importlib.import_module(module_name)


def _install_dummy_ats_parser():
    """
    Provide a tiny in-memory ats_parser so tests don't need the real heavy parser stack.
    resume_parser imports: parse_file, adapt_for_backend.
    """
    dummy = types.ModuleType("ats_parser")
    calls = {"parse_file": 0, "adapt_for_backend": 0}

    def parse_file(path: str):
        calls["parse_file"] += 1
        # Minimal shape; resume_parser will pass this into adapt_for_backend()
        return {"raw_text": "hello from pdf", "skills": ["Python"]}

    def adapt_for_backend(res: dict):
        calls["adapt_for_backend"] += 1
        # Match the backend's expected keys (safe defaults)
        return {
            "raw_text": res.get("raw_text", ""),
            "name": "Test User",
            "first_name": "Test",
            "middle_name": "",
            "last_name": "User",
            "phone": "",
            "email": "",
            "links": [],
            "skills": res.get("skills", ""),
            "education": [],
            "experience": [],
            "languages": "",
            "projects": "",
        }

    dummy.parse_file = parse_file
    dummy.adapt_for_backend = adapt_for_backend
    sys.modules["ats_parser"] = dummy
    return calls


def test_parse_resume_pdf_calls_parse_pipeline(tmp_path):
    calls = _install_dummy_ats_parser()

    resume_parser = _import_fresh("resume_parser")

    out = resume_parser.parse_resume(str(tmp_path / "x.pdf"))

    assert calls["parse_file"] == 1
    assert calls["adapt_for_backend"] == 1
    assert out["raw_text"] == "hello from pdf"
    assert out["name"] == "Test User"


def test_parse_resume_unsupported_extension_raises():
    _install_dummy_ats_parser()
    resume_parser = _import_fresh("resume_parser")

    with pytest.raises(ValueError):
        resume_parser.parse_resume("x.txt")


def test_backend_allowed_file_and_init_db(tmp_path, monkeypatch):
    # Make backend use temp paths; backend runs init_db() at import time.
    monkeypatch.setenv("DB_PATH", str(tmp_path / "test.db"))
    monkeypatch.setenv("UPLOAD_DIR", str(tmp_path / "uploads"))

    _install_dummy_ats_parser()

    backend = _import_fresh("backend")

    assert backend.allowed_file("resume.pdf") is True
    assert backend.allowed_file("resume.docx") is True
    assert backend.allowed_file("resume.exe") is False

    # backend.init_db() is called at module import, so DB should exist.
    assert (tmp_path / "test.db").exists()



// Summary: wrote 28 files, skipped 55995 files.
