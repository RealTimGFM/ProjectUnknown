================================================================================
PROJECT SUMMARY
================================================================================

Generated: 2025-09-15T02:32:21Z
Root: C:\Users\User\Documents\GitHub\ProjectUnknown
Python: 3.13.5

================================================================================
PROJECT TREE
================================================================================

ProjectUnknown/
├── templates/
│   └── index.html
├── uploads/
│   └── QuyVuLuong_CV.pdf
├── .gitattributes
├── backend.py
├── dump.txt
├── dump_project.py
├── README.md
├── requirements.txt
└── resume_parser.py

Directories: 2  Files: 9

================================================================================
FILE CONTENTS
================================================================================

================================================================================
// Path: README.md
================================================================================

# Mini ATS — Structured Resume Scanner (Phase)

A minimal ATS-style web app:
- Upload a **PDF resume**.
- Backend parses sections and extracts **structured fields** (Experience, Education, Projects).
- Data is stored in **SQLite** with JSON columns.
- Web UI shows **text boxes per field**; you can edit and **save** back to DB.

---

## Features

- Section-aware parsing (SUMMARY / EXPERIENCE / EDUCATION / PROJECTS / SKILLS / LANGUAGES).
- Heuristics for dates and roles; calculates **duration (months)** when possible.
- Stores arrays (lists of dicts) as **JSON** in SQLite.
- Inline **edit & save** for each candidate.
- Safe parser (guards against missing sections / malformed bullets).

---

## Project Structure
ProjectUnknown/
├─ backend.py # Flask app + DB CRUD
├─ resume_parser.py # PDF → structured JSON (experience/education/projects)
├─ templates/
│ └─ index.html # Upload + editable cards UI
├─ uploads/ # Saved resumes (created on first upload)
├─ database.db # SQLite (auto-created)
├─ requirements.txt
└─ README.md
## Quickstart

> Tested on **Python 3.13**. Works on 3.10+.

### 1) Create venv & install deps
**Windows (PowerShell):**
```powershell
python -m venv .venv
.\.venv\Scripts\Activate.ps1
pip install -r requirements.txt

python backend.py
http://127.0.0.1:5000
# stop the app, then:
del database.db         # PowerShell
# or
rm database.db          # bash/zsh
# start the app again so it recreates the table

================================================================================
// Path: backend.py
================================================================================

# backend.py
from flask import Flask, request, render_template, jsonify
import sqlite3, os, json
from resume_parser import parse_resume
from werkzeug.utils import secure_filename

app = Flask(__name__)
DB_PATH = "database.db"
ALLOWED_EXTS = {"pdf"}  # add "doc","docx" later if you implement those
app.config["MAX_CONTENT_LENGTH"] = 10 * 1024 * 1024  # 10 MB

def allowed_file(filename: str) -> bool:
    return "." in filename and filename.rsplit(".", 1)[1].lower() in ALLOWED_EXTS

def init_db():
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute(
        """CREATE TABLE IF NOT EXISTS candidates (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            name TEXT,
            summary TEXT,
            education TEXT,   -- JSON
            experience TEXT,  -- JSON
            projects TEXT,    -- JSON
            skills TEXT,      -- CSV
            languages TEXT,   -- CSV
            raw_text TEXT
        )"""
    )
    conn.commit()
    conn.close()


@app.route("/", methods=["GET", "POST"])
def index():
    if request.method == "POST":
        file = request.files.get("resume")
        if file and allowed_file(file.filename):
            os.makedirs("uploads", exist_ok=True)
            path = os.path.join("uploads", secure_filename(file.filename))
            file.save(path)

            parsed = parse_resume(path)

            conn = sqlite3.connect(DB_PATH)
            c = conn.cursor()
            c.execute(
                """INSERT INTO candidates 
                   (name, summary, education, experience, projects, skills, languages, raw_text)
                   VALUES (?,?,?,?,?,?,?,?)""",
                (
                    parsed["name"],
                    parsed.get("summary", ""),
                    json.dumps(parsed.get("education", []), ensure_ascii=False),
                    json.dumps(parsed.get("experience", []), ensure_ascii=False),
                    json.dumps(parsed.get("projects", []), ensure_ascii=False),
                    parsed.get("skills", ""),
                    parsed.get("languages", ""),
                    parsed.get("raw_text", ""),
                ),
            )
            conn.commit()
            conn.close()
        else:
            return render_template("index.html", candidates=[], json=json)

    # fetch
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute(
        "SELECT id, name, summary, education, experience, projects, skills, languages FROM candidates ORDER BY id DESC"
    )
    rows = c.fetchall()
    conn.close()

    # pass json module so we can json.loads in template
    return render_template("index.html", candidates=rows, json=json)


@app.post("/update/<int:cand_id>")
def update_candidate(cand_id: int):
    payload = request.get_json(force=True, silent=True) or {}
    # Only accept fields we know
    name = payload.get("name", "")
    summary = payload.get("summary", "")
    education = json.dumps(payload.get("education", []), ensure_ascii=False)
    experience = json.dumps(payload.get("experience", []), ensure_ascii=False)
    projects = json.dumps(payload.get("projects", []), ensure_ascii=False)
    skills = payload.get("skills", "")
    languages = payload.get("languages", "")

    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute(
        """UPDATE candidates SET
           name=?, summary=?, education=?, experience=?, projects=?, skills=?, languages=?
           WHERE id=?""",
        (name, summary, education, experience, projects, skills, languages, cand_id),
    )
    conn.commit()
    conn.close()
    return jsonify({"ok": True})


if __name__ == "__main__":
    init_db()
    app.run(debug=True)


================================================================================
// Path: dump.txt
================================================================================



================================================================================
// Path: dump_project.py
================================================================================

import os
import sys
import argparse
from datetime import datetime
from typing import Iterable, List, Set, Tuple

# ---------- Defaults tuned for StockAI ----------
DEFAULT_ROOT = "."
DEFAULT_OUTPUT = "dump.txt"
DEFAULT_MAX_FILE_SIZE = 1 * 1024 * 1024  # 1 MB

# Folders we usually exclude from **tree** to avoid noise; use --tree-all to include anyway
TREE_EXCLUDE_ANYWHERE: Set[str] = {".git", ".venv", "__pycache__", ".idea", ".vscode"}

# Folders we exclude from **content**, but still show in the tree
CONTENT_EXCLUDE_ANYWHERE: Set[str] = {
    ".git", ".venv", "__pycache__", ".idea", ".vscode", "node_modules",
    "dist", "build", ".mastra",
    # project artifacts
    "backtests", "notebooks",
}

# Filenames to ignore for content
IGNORE_FILES_ANYWHERE: Set[str] = {
    ".env", ".env.local", ".python-version", "Pipfile.lock",
    "package-lock.json", "tsconfig.json", "cookies.txt",
}

# Always include these names (even without extensions) in content
INCLUDE_FILENAMES: Set[str] = {"Makefile", "Dockerfile"}

# Binary-ish extensions (content skipped; still listed in tree)
BINARY_EXTS: Set[str] = {
    # archives / binaries
    ".zip", ".gz", ".tar", ".rar", ".7z", ".exe", ".dll", ".so", ".a",
    # db / parquet / arrow
    ".sqlite", ".sqlite3", ".db", ".db-journal", ".parquet", ".arrow",
    # images
    ".png", ".jpg", ".jpeg", ".gif", ".bmp", ".tiff", ".ico", ".webp",
    # docs
    ".pdf", ".doc", ".docx", ".ppt", ".pptx", ".xls", ".xlsx",
    # audio/video
    ".mp3", ".wav", ".m4a", ".mp4", ".mov", ".avi", ".mkv",
}

# Text/code extensions included by default for content
DEFAULT_INCLUDE_EXTS: Set[str] = {
    ".py", ".toml", ".yaml", ".yml", ".json", ".md", ".txt", ".cfg", ".ini",
    ".sql", ".sh", ".bat", ".ps1", ".html", ".css", ".js", ".ts", ".tsx", ".jsx",
}
# ------------------------------------------------

def parse_args():
    p = argparse.ArgumentParser(description="Dump project TREE + text/code contents into a single file.")
    p.add_argument("--root", default=DEFAULT_ROOT, help="Root directory to scan")
    p.add_argument("--output", default=DEFAULT_OUTPUT, help="Output file path")
    p.add_argument("--max-size", type=int, default=DEFAULT_MAX_FILE_SIZE, help="Max file size (bytes) for content")
    p.add_argument("--include-ext", default=",".join(sorted(DEFAULT_INCLUDE_EXTS)),
                   help="Comma-separated list of file extensions to include as content (e.g. .py,.toml,.yaml)")
    p.add_argument("--tree-all", action="store_true", help="Include ALL directories in the tree (even .git/.venv)")
    p.add_argument("--no-content", action="store_true", help="Only print the tree (no file contents)")
    p.add_argument("--placeholders", action="store_true",
                   help="Write placeholder blocks for skipped files (binary/large/not-included)")
    return p.parse_args()

def _normalize_exts(s: str) -> Set[str]:
    exts = set()
    for raw in s.split(","):
        e = raw.strip()
        if not e:
            continue
        if not e.startswith("."):
            e = "." + e
        exts.add(e.lower())
    return exts

def is_probably_binary(filepath: str, chunk_size: int = 1024) -> bool:
    try:
        with open(filepath, "rb") as f:
            chunk = f.read(chunk_size)
            if not chunk:
                return False
            if b"\0" in chunk:
                return True
            text_chars = bytearray({7,8,9,10,12,13,27} | set(range(0x20, 0x100)) - {0x7F})
            non_text = sum(1 for b in chunk if b not in text_chars)
            return (non_text / max(1, len(chunk))) > 0.30
    except Exception:
        return True

def should_hide_in_tree(name: str, include_all: bool) -> bool:
    return (name in TREE_EXCLUDE_ANYWHERE) and (not include_all)

def should_skip_content_dir(name: str) -> bool:
    return name in CONTENT_EXCLUDE_ANYWHERE

def should_include_content(fname: str, include_exts: Set[str]) -> bool:
    if fname in INCLUDE_FILENAMES:
        return True
    base, ext = os.path.splitext(fname)
    ext = ext.lower()
    if ext in BINARY_EXTS:
        return False
    if include_exts and ext not in include_exts:
        return False
    return True

def tree_lines(root: str, include_all: bool) -> Tuple[List[str], int, int]:
    """
    Return (lines, dir_count, file_count) for a pretty tree.
    """
    lines: List[str] = []
    dir_count = 0
    file_count = 0

    def walk(dir_path: str, prefix: str = ""):
        nonlocal dir_count, file_count
        try:
            entries = sorted(os.scandir(dir_path), key=lambda e: (not e.is_dir(), e.name.lower()))
        except PermissionError:
            return
        # filter only for tree display
        entries = [e for e in entries if not (e.is_dir() and should_hide_in_tree(e.name, include_all))]
        total = len(entries)
        for idx, e in enumerate(entries):
            connector = "└── " if idx == total - 1 else "├── "
            if e.is_dir():
                lines.append(f"{prefix}{connector}{e.name}/")
                dir_count += 1
                next_prefix = f"{prefix}{'    ' if idx == total - 1 else '│   '}"
                walk(e.path, next_prefix)
            else:
                file_count += 1
                lines.append(f"{prefix}{connector}{e.name}")

    root_label = os.path.basename(os.path.abspath(root)) or root
    lines.append(f"{root_label}/")
    walk(root)
    return lines, dir_count, file_count

def write_header(dump, title: str):
    sep = "=" * max(80, len(title) + 10)
    dump.write(f"{sep}\n")
    dump.write(f"{title}\n")
    dump.write(f"{sep}\n\n")

def write_file_header(dump, rel_path: str):
    header = f"// Path: {rel_path}"
    sep_len = max(80, len(header))
    dump.write("=" * sep_len + "\n")
    dump.write(header + "\n")
    dump.write("=" * sep_len + "\n\n")

def iter_all_files(root: str) -> Iterable[str]:
    for cur_root, dirs, files in os.walk(root, topdown=True):
        dirs[:] = sorted(dirs)
        for fname in sorted(files):
            yield os.path.join(cur_root, fname)

def main():
    args = parse_args()
    root = args.root
    out_path = args.output
    include_exts = _normalize_exts(args.include_ext)

    if not os.path.isdir(root):
        print(f"ERROR: root directory not found: {root}")
        sys.exit(1)

    with open(out_path, "w", encoding="utf-8", errors="ignore") as dump:
        # 1) Project metadata
        write_header(dump, "PROJECT SUMMARY")
        dump.write(f"Generated: {datetime.utcnow().isoformat(timespec='seconds')}Z\n")
        dump.write(f"Root: {os.path.abspath(root)}\n")
        dump.write(f"Python: {sys.version.split()[0]}\n\n")

        # 2) Tree
        write_header(dump, "PROJECT TREE")
        lines, dcnt, fcnt = tree_lines(root, include_all=args.tree_all)
        dump.write("\n".join(lines) + "\n\n")
        dump.write(f"Directories: {dcnt}  Files: {fcnt}\n\n")

        if args.no_content:
            print(f"Done (tree only). Wrote {out_path}")
            return

        # 3) File contents (text/code only)
        write_header(dump, "FILE CONTENTS")
        processed = 0
        skipped = 0

        for fpath in iter_all_files(root):
            rel = os.path.relpath(fpath, root).replace("\\", "/")
            fname = os.path.basename(fpath)
            parent = os.path.basename(os.path.dirname(fpath))

            # Skip content if under excluded dirs
            if parent in CONTENT_EXCLUDE_ANYWHERE or any(p in CONTENT_EXCLUDE_ANYWHERE for p in rel.split("/") if p):
                # still optionally write placeholder
                if args.placeholders:
                    write_file_header(dump, rel)
                    dump.write(f"// [skipped: directory excluded from content]\n\n")
                skipped += 1
                continue

            # Skip content by rule
            if not should_include_content(fname, include_exts):
                if args.placeholders:
                    write_file_header(dump, rel)
                    dump.write(f"// [skipped: extension not in include list]\n\n")
                skipped += 1
                continue

            # Size & binary checks
            try:
                size = os.path.getsize(fpath)
            except OSError as e:
                if args.placeholders:
                    write_file_header(dump, rel)
                    dump.write(f"// [skipped: stat error: {e}]\n\n")
                skipped += 1
                continue

            if size > args.max_size:
                if args.placeholders:
                    write_file_header(dump, rel)
                    dump.write(f"// [skipped: large file ~{size} bytes]\n\n")
                skipped += 1
                continue

            if is_probably_binary(fpath):
                if args.placeholders:
                    write_file_header(dump, rel)
                    dump.write(f"// [skipped: binary-like file]\n\n")
                skipped += 1
                continue

            # Emit content
            try:
                with open(fpath, "r", encoding="utf-8", errors="ignore") as src:
                    content = src.read()
                write_file_header(dump, rel)
                dump.write(content)
                dump.write("\n\n")
                processed += 1
                if processed % 50 == 0:
                    print(f"... wrote {processed} files")
            except Exception as e:
                if args.placeholders:
                    write_file_header(dump, rel)
                    dump.write(f"// [skipped: read error: {e}]\n\n")
                skipped += 1
                continue

        dump.write(f"\n// Summary: wrote {processed} files, skipped {skipped} files.\n")

    print(f"Done. TREE + contents written to {out_path}")

if __name__ == "__main__":
    main()


================================================================================
// Path: requirements.txt
================================================================================

Flask>=3.0.3
pdfplumber>=0.11.0
pdfminer.six>=20240706
Pillow>=10.2.0
python-dateutil>=2.9.0.post0



================================================================================
// Path: resume_parser.py
================================================================================

import re
import pdfplumber
from datetime import datetime
from dateutil import parser as dateparser
from typing import List, Dict, Tuple

MONTHS = r"(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Sept|Oct|Nov|Dec)[a-z]*"
YEAR = r"(19|20)\d{2}"
DATE_RE = re.compile(
    rf"(?P<start>({MONTHS}\s+{YEAR}|{YEAR}))\s*[-–—]\s*(?P<end>({MONTHS}\s+{YEAR}|{YEAR}|Present|Current))",
    re.IGNORECASE,
)

CONTACT_EMAIL_RE = re.compile(r"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}")
CONTACT_PHONE_RE = re.compile(r"(\+?\d[\d\s().-]{7,}\d)")
URL_RE = re.compile(r"(https?://[^\s]+|(?:www\.)?(?:github|linkedin)\.com[^\s]*)", re.I)
LOCATION_HINTS = ["Montreal", "QC", "Canada", "Ho Chi Minh", "Viet", "Vietnam"]

def _norm(s: str) -> str:
    return re.sub(r"\s+", " ", s or "").strip()

def _read_pdf_text(path: str) -> str:
    try:
        with pdfplumber.open(path) as pdf:
            return "\n".join((p.extract_text() or "") for p in pdf.pages) + "\n"
    except Exception:
        return ""

def _split_sections(text: str) -> dict:
    sections, current = {}, None
    aliases = {
        "SUMMARY": {"summary", "professional summary", "profile"},
        "EXPERIENCE": {"experience", "work experience", "employment", "professional experience"},
        "EDUCATION": {"education", "academic background"},
        "PROJECTS": {"projects", "personal projects", "notable projects"},
        "SKILLS": {"skills", "technical skills"},
        "LANGUAGES": {"languages"},
    }
    for raw in text.splitlines():
        line = _norm(raw)
        if not line:
            continue
        low = line.lower()
        hit = None
        for key, names in aliases.items():
            if low in names:
                hit = key; break
        if hit:
            current = hit; sections.setdefault(current, []); continue
        if current: sections[current].append(line)
    return sections

def _parse_date_range(s: str) -> Tuple[str|None, str|None, int|None]:
    m = DATE_RE.search(s)
    if not m:
        return None, None, None
    start_raw, end_raw = m.group("start"), m.group("end")
    try:
        start_dt = dateparser.parse(start_raw, fuzzy=True)
    except Exception:
        start_dt = None
    # Use NOW if Present/Current
    if end_raw and re.search(r"present|current", end_raw, re.I):
        end_dt = datetime.utcnow()
    else:
        try:
            end_dt = dateparser.parse(end_raw, fuzzy=True) if end_raw else None
        except Exception:
            end_dt = None
    duration = None
    if start_dt and end_dt:
        duration = (end_dt.year - start_dt.year) * 12 + (end_dt.month - start_dt.month)
    return start_raw, end_raw, duration

def _extract_contacts(text: str) -> Dict[str, str]:
    phone = CONTACT_PHONE_RE.search(text)
    email = CONTACT_EMAIL_RE.search(text)
    urls = URL_RE.findall(text)
    # best-effort location: look for common hints or "City, Region"
    loc = ""
    for line in text.splitlines():
        if any(h in line for h in LOCATION_HINTS) or re.search(r"[A-Z][a-z]+(?:,?\s+[A-Z][a-z]+)+(?:,\s*[A-Za-z]+)?", line):
            loc = _norm(line); break
    return {
        "phone": _norm(phone.group(0)) if phone else "",
        "email": _norm(email.group(0)) if email else "",
        "urls": " ".join(_norm(u) for u in urls),
        "location": loc,
    }

def _parse_experience(lines: List[str]) -> List[Dict]:
    items, cur = [], None
    bullet_re = re.compile(r"^\s*[-*•]\s+")
    company_hint = re.compile(r"\b(Inc\.?|Corp\.?|LLC|Ltd\.?|Company|Capital|Systems|Labs|Studio|Technologies?)\b", re.I)

    for ln in lines:
        if DATE_RE.search(ln):
            if cur:
                # finalize skills arrays empty for now as requested
                cur["skills_used_tech"] = []
                cur["skills_used_soft"] = []
                items.append(cur)
            start, end, dur = _parse_date_range(ln)
            head = DATE_RE.split(ln)[0].strip(" -–—|")
            parts = [p.strip() for p in re.split(r"[|•\-–—]", head) if p.strip()]
            position = parts[0] if parts else ""
            # try to find company: next part with company-ish token or proper-cased phrase
            company = ""
            for p in parts[1:]:
                if company_hint.search(p) or p.istitle():
                    company = p; break
            cur = {
                "position": _norm(position),
                "company_name": _norm(company),
                "location": "",
                "start_date": start,
                "end_date": end,
                "duration_months": dur,
                "description": "",
                "skills_used_tech": [],
                "skills_used_soft": [],
            }
            continue

        if cur:
            clean = bullet_re.sub("", ln)
            cur["description"] = (cur["description"] + ("\n" if cur["description"] else "") + clean).strip()
            if not cur["company_name"] and company_hint.search(ln):
                cur["company_name"] = _norm(ln)
            if not cur["location"]:
                if any(h in ln for h in LOCATION_HINTS):
                    cur["location"] = _norm(ln)

    if cur:
        cur["skills_used_tech"] = []
        cur["skills_used_soft"] = []
        items.append(cur)

    # post-fix: if company missing but description mentions "Machine Builder Inc", set it
    for e in items:
        if not e["company_name"] and re.search(r"Machine Builder Inc", e["description"], re.I):
            e["company_name"] = "Machine Builder Inc."
        if not e["location"] and re.search(r"Montreal", e["description"], re.I):
            e["location"] = "Montreal"
        # recompute duration if end is Present/Current and we missed it
        if e["start_date"] and (not e["end_date"] or re.search(r"present|current", e["end_date"] or "", re.I)):
            _, _, e["duration_months"] = _parse_date_range(f"{e['start_date']} - Present")

    return items

def _parse_education(lines: List[str]) -> List[Dict]:
    blocks, buf = [], []
    flush_tokens = ("University", "College", "School", "Institute", "Diploma", "Bachelor", "Master", "DEC")

    def flush():
        if not buf: return
        text = " | ".join(buf)
        start, end, _ = _parse_date_range(text)
        level_match = re.search(r"(High School Diploma|Diploma|Bachelor(?:'s)?|Master(?:'s)?|DEC|College Studies DEC|BSc|MSc|PhD)", text, re.I)
        level = level_match.group(1) if level_match else ""
        field_match = re.search(r"(?:in|of)\s+([A-Za-z &/+-]{2,})", text, re.I)
        field = _norm(field_match.group(1)) if field_match else ""
        # Split around the dates to find school and location in the tail
        tail = DATE_RE.split(text)
        after = tail[-1] if len(tail) >= 3 else ""
        # school = first org-looking fragment
        school = ""
        for p in [p.strip() for p in re.split(r"[|•\-–—]", text) if p.strip()]:
            if re.search(r"(University|College|School|Institute)", p, re.I):
                school = p; break
        if not school:
            school = _norm(after.split("|")[0])
        # location = last comma phrase in tail
        loc_match = re.search(r"([A-Z][a-z]+(?:,?\s+[A-Z][a-z]+)+(?:,\s*[A-Za-z]+)?)", after)
        location = _norm(loc_match.group(1)) if loc_match else ""
        blocks.append({
            "level": _norm(level),
            "field": _norm(field),
            "school_name": _norm(school),
            "location": location,
            "start_year": start,
            "end_year": end,
        })
        buf.clear()

    for ln in lines:
        if any(t.lower() in ln.lower() for t in flush_tokens) and buf:
            flush()
        buf.append(ln)
    flush()
    return [b for b in blocks if any(b.values())]

def _parse_projects(lines: List[str]) -> List[Dict]:
    items, buf = [], []
    def dates_in(s: str) -> str:
        m = DATE_RE.search(s)
        return m.group(0) if m else ""
    def clean_title(s: str) -> str:
        s = re.sub(DATE_RE, "", s)
        s = re.sub(r"\b(20\d{2}|19\d{2})\b", "", s)
        return _norm(s)

    def flush():
        if not buf: return
        text = "\n".join(buf).strip()
        title_line = buf[0] if buf else ""
        items.append({
            "title": clean_title(title_line),           # name only
            "when": dates_in(" ".join(buf)),            # year/month-year here
            "description": text,
        })
        buf.clear()

    for ln in lines:
        # new project if a clear title line (no bullet) followed by details
        if not ln.startswith(("•", "-", "*")) and buf:
            flush()
        buf.append(ln)
    flush()
    return items

def parse_resume(filepath: str) -> Dict:
    text = _read_pdf_text(filepath)
    lines = [l for l in (text or "").splitlines()]
    # name = first non-empty line
    name = next((_norm(l) for l in lines if _norm(l)), "Unknown")

    sections = _split_sections(text)
    contacts = _extract_contacts(text)

    education = _parse_education(sections.get("EDUCATION", []))
    experience = _parse_experience(sections.get("EXPERIENCE", []))
    projects = _parse_projects(sections.get("PROJECTS", []))

    # SUMMARY = contacts only, in one line (phone, urls, email, location)
    summary = " ".join(
        p for p in [
            contacts.get("phone",""),
            contacts.get("urls",""),
            contacts.get("email",""),
            contacts.get("location",""),
        ] if p
    )

    return {
        "name": name,
        "summary": summary,
        "education": education,
        "experience": experience,
        "projects": projects,
        "skills": "",      # keep as CSV (OK to fill later)
        "languages": "",   # not needed in UI; keep empty for DB compatibility
        "raw_text": text or "",
    }


================================================================================
// Path: templates/index.html
================================================================================

<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>ATS Scanner</title>
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <style>
    :root { --bg:#0b0f1a; --card:#0f1422; --muted:#9aa3af; --accent:#3b82f6; --border:#1f2937; --text:#e5e7eb; }
    * { box-sizing: border-box; }
    body { margin:0; font-family: Inter, system-ui, -apple-system, Segoe UI, Roboto, sans-serif; background:var(--bg); color:var(--text); }
    header { padding:20px; background:#0a0f1d; border-bottom:1px solid var(--border); }
    header h1 { margin:0; font-size:20px; }
    main { max-width:1100px; margin:20px auto; padding:0 16px; }
    .upload { background:var(--card); padding:16px; border-radius:12px; border:1px solid var(--border); display:flex; gap:12px; align-items:center; }
    .upload input[type=file]{ flex:1; color:var(--muted); }
    .upload button{ background:var(--accent); color:#fff; border:none; padding:10px 14px; border-radius:8px; cursor:pointer; }
    .card { background:var(--card); border:1px solid var(--border); border-radius:14px; padding:18px; margin:16px 0; box-shadow:0 2px 10px rgba(0,0,0,0.12); }
    .grid { display:grid; grid-template-columns: repeat(12, 1fr); gap:12px; }
    .col-12{ grid-column: span 12; } .col-6{ grid-column: span 6; } .col-4{ grid-column: span 4; } .col-3{ grid-column: span 3; }
    label { font-size:12px; color:var(--muted); display:block; margin-bottom:6px; }
    input, textarea { width:100%; padding:10px; border:1px solid var(--border); border-radius:10px; background:#0b1120; color:var(--text); }
    textarea { min-height:80px; resize:vertical; }
    .row { display:flex; gap:10px; align-items:center; }
    .badge { display:inline-block; padding:4px 10px; background:#1f2a44; color:#93c5fd; border-radius:999px; font-size:12px; margin-right:6px; border:1px solid var(--border); }
    .btn { border:1px solid var(--border); background:#0b1120; color:var(--text); padding:8px 12px; border-radius:8px; cursor:pointer; }
    .btn.primary { background:var(--accent); color:#fff; border-color:var(--accent); }
    .section { margin-top:16px; padding-top:16px; border-top:1px dashed var(--border); }
    .muted { color:var(--muted); }
  </style>
</head>
<body>
  <header><h1>ATS Scanner — Structured Resume Parser</h1></header>
  <main>
    <form class="upload" method="POST" enctype="multipart/form-data">
      <input type="file" name="resume" accept=".pdf" required>
      <button type="submit">Upload & Parse</button>
    </form>

    {% for c in candidates %}
      {% set cid = c[0] %}
      {% set name = c[1] %}
      {% set summary = c[2] or "" %}
      {% set edu = json.loads(c[3] or "[]") %}
      {% set exp = json.loads(c[4] or "[]") %}
      {% set pro = json.loads(c[5] or "[]") %}
      {% set skills = c[6] or "" %}

      <div class="card" id="card-{{cid}}">
        <div class="row" style="justify-content:space-between;">
          <h2 style="margin:0">{{ name or "Unnamed Candidate" }}</h2>
          <div>
            <span class="badge">ID #{{cid}}</span>
            <button type="button" class="btn btn-edit" data-cid="{{ cid }}">Edit</button>
            <button type="button" class="btn primary btn-save" data-cid="{{ cid }}">Save Changes</button>
          </div>
        </div>

        <div class="grid section">
          <div class="col-12">
            <label>Full Name</label>
            <input id="name-{{cid}}" value="{{ name }}">
          </div>
          <div class="col-12">
            <label>Summary (contacts only: phone · links · email · location)</label>
            <textarea id="summary-{{cid}}">{{ summary }}</textarea>
          </div>
        </div>

        <div class="section">
          <h3>Experience</h3>
          {% if exp|length == 0 %}<p class="muted">No experience parsed.</p>{% endif %}
          {% for e in exp %}
          <div class="grid" style="margin-bottom:12px;" data-exp="{{loop.index0}}">
            <div class="col-4">
              <label>Position</label>
              <input id="exp-{{cid}}-{{loop.index0}}-position" value="{{ e.get('position','') }}">
            </div>
            <div class="col-4">
              <label>Company</label>
              <input id="exp-{{cid}}-{{loop.index0}}-company_name" value="{{ e.get('company_name', e.get('company','')) }}">
            </div>
            <div class="col-4">
              <label>Location</label>
              <input id="exp-{{cid}}-{{loop.index0}}-location" value="{{ e.get('location','') }}">
            </div>
            <div class="col-4">
              <label>Start Date</label>
              <input id="exp-{{cid}}-{{loop.index0}}-start_date" value="{{ e.get('start_date','') }}">
            </div>
            <div class="col-4">
              <label>End Date</label>
              <input id="exp-{{cid}}-{{loop.index0}}-end_date" value="{{ e.get('end_date','') }}">
            </div>
            <div class="col-4">
              <label>Duration (months)</label>
              <input id="exp-{{cid}}-{{loop.index0}}-duration_months" value="{{ e.get('duration_months','') }}">
            </div>
            <div class="col-12">
              <label>Role Description</label>
              <textarea id="exp-{{cid}}-{{loop.index0}}-description">{{ e.get('description','') }}</textarea>
            </div>
          </div>
          {% endfor %}
        </div>

        <div class="section">
          <h3>Education</h3>
          {% set edu_list = edu if edu|length > 0 else [ {'level':'','field':'','school_name':'','location':'','start_year':'','end_year':''} ] %}
          {% for ed in edu_list %}
          <div class="grid" style="margin-bottom:12px;" data-edu="{{loop.index0}}">
            <div class="col-4">
              <label>Level</label>
              <input id="edu-{{cid}}-{{loop.index0}}-level" value="{{ ed.get('level', ed.get('degree','')) }}">
            </div>
            <div class="col-4">
              <label>Field</label>
              <input id="edu-{{cid}}-{{loop.index0}}-field" value="{{ ed.get('field','') }}">
            </div>
            <div class="col-4">
              <label>School</label>
              <input id="edu-{{cid}}-{{loop.index0}}-school_name" value="{{ ed.get('school_name', ed.get('school','')) }}">
            </div>
            <div class="col-6">
              <label>Location</label>
              <input id="edu-{{cid}}-{{loop.index0}}-location" value="{{ ed.get('location','') }}">
            </div>
            <div class="col-3">
              <label>Start Year</label>
              <input id="edu-{{cid}}-{{loop.index0}}-start_year" value="{{ ed.get('start_year','') }}">
            </div>
            <div class="col-3">
              <label>End Year</label>
              <input id="edu-{{cid}}-{{loop.index0}}-end_year" value="{{ ed.get('end_year','') }}">
            </div>
          </div>
          {% endfor %}
        </div>

        <div class="section">
          <h3>Projects</h3>
          {% set pro_list = pro if pro|length > 0 else [ {'title':'','when':'','description':''} ] %}
          {% for p in pro_list %}
          <div class="grid" style="margin-bottom:12px;" data-pro="{{loop.index0}}">
            <div class="col-6">
              <label>Title</label>
              <input id="pro-{{cid}}-{{loop.index0}}-title" value="{{ p.get('title','') }}">
            </div>
            <div class="col-6">
              <label>When/Notes</label>
              <input id="pro-{{cid}}-{{loop.index0}}-when" value="{{ p.get('when','') }}">
            </div>
            <div class="col-12">
              <label>Description</label>
              <textarea id="pro-{{cid}}-{{loop.index0}}-description">{{ p.get('description','') }}</textarea>
            </div>
          </div>
          {% endfor %}
        </div>

        <div class="grid section">
          <div class="col-12">
            <label>Skills (technical; CSV)</label>
            <input id="skills-{{cid}}" value="{{ skills }}">
          </div>
        </div>
      </div>
    {% endfor %}
  </main>

  <script>
    function toggleEdit(cid){
      const card = document.getElementById(`card-${cid}`);
      const inputs = card.querySelectorAll('input, textarea');
      const ro = inputs.length ? inputs[0].readOnly : false;
      inputs.forEach(el => el.readOnly = !ro);
    }

    function collectList(prefix, cid, attrNames){
      const card = document.getElementById(`card-${cid}`);
      const blocks = [];
      card.querySelectorAll(`[data-${prefix}]`).forEach(block=>{
        const idx = block.getAttribute(`data-${prefix}`);
        const obj = {};
        attrNames.forEach(name=>{
          const el = document.getElementById(`${prefix}-${cid}-${idx}-${name}`);
          obj[name] = el ? el.value : "";
        });
        blocks.push(obj);
      });
      return blocks;
    }

    async function saveCandidate(cid){
      const name = document.getElementById(`name-${cid}`).value;
      const summary = document.getElementById(`summary-${cid}`).value;

      const experience = collectList('exp', cid, [
        'position','company_name','location','start_date','end_date','duration_months','description'
      ]).map(e=>{
        e.duration_months = e.duration_months ? parseInt(e.duration_months,10) : null;
        e.skills_used_tech = [];  // per your instruction (fill later)
        e.skills_used_soft = [];
        return e;
      });

      const education = collectList('edu', cid, [
        'level','field','school_name','location','start_year','end_year'
      ]);

      const projects = collectList('pro', cid, ['title','when','description']);

      const skills = document.getElementById(`skills-${cid}`).value;
      const languages = ""; // UI removed

      const res = await fetch(`/update/${cid}`, {
        method: 'POST',
        headers: {'Content-Type':'application/json'},
        body: JSON.stringify({ name, summary, education, experience, projects, skills, languages })
      });
      alert(res.ok ? 'Saved!' : 'Save failed');
    }

    // delegated listeners (no inline events)
    document.addEventListener('click', (e)=>{
      const editBtn = e.target.closest('.btn-edit');
      if (editBtn) { toggleEdit(parseInt(editBtn.dataset.cid,10)); return; }
      const saveBtn = e.target.closest('.btn-save');
      if (saveBtn) { saveCandidate(parseInt(saveBtn.dataset.cid,10)); }
    });
  </script>
</body>
</html>



// Summary: wrote 7 files, skipped 2194 files.
